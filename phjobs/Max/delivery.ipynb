{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phcli Jupyter Template\n",
    "# \n",
    "# 使用手册：\n",
    "# 1. 请将全局变量定义在第一个输入区内\n",
    "# 2. Phcli 会自动在第二个输入区初始化 Spark Session\n",
    "# 3. 所有 print 会在 phcli maxauto dag 后自动转为 logger.debug() 方法\n",
    "# 4. 请在第三个输入区开始编码，phcli maxauto dag 后会全部归类为一个方法\n",
    "\n",
    "\n",
    "# Config defined in here\n",
    "\n",
    "############## == config == ###################\n",
    "job_name = \"delivery\"\n",
    "job_runtime = \"python3\"\n",
    "job_command = \"submit\"\n",
    "job_timeout = 720.0\n",
    "############## == config == ###################\n",
    "\n",
    "\n",
    "# Variables defined in here\n",
    "\n",
    "############## == input args == ###################\n",
    "project_name = \"Empty\"\n",
    "time_left = \"Empty\"\n",
    "time_right = \"Empty\"\n",
    "out_dir = \"Empty\"\n",
    "extract_path = \"s3a://ph-stream/common/public/max_result/0.0.5/max_standard\"\n",
    "max_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "############## == input args == ###################\n",
    "\n",
    "############## == output args == ###################\n",
    "c = 'abc'\n",
    "d = 'def'\n",
    "############## == output args == ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# ENV\n",
    "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/local/spark\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAWPBDTVEAEU44ZAGT\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"cn-northwest-1\"\n",
    "\n",
    "# prepare\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"ywyuan write Max.delivery in jupyter using python3\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .config('spark.sql.codegen.wholeStage', False) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "if access_key:\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.cn-northwest-1.amazonaws.com.cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from phcli.ph_logs.ph_logs import phs3logger\n",
    "# from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import functions as func\n",
    "import os\n",
    "import re\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, col, udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "'''\n",
    "project_name = \"Takeda\"\n",
    "time_left = \"201801\"\n",
    "time_right = \"202012\"\n",
    "out_dir = \"202012\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "# MAX数据交付"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "## 输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "time_left = int(time_left)\n",
    "time_right = int(time_right)\n",
    "\n",
    "product_map_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/prod_mapping\"\n",
    "max_standard_path = extract_path + \"/\" + project_name + \"_max_standard\"\n",
    "province_city_mapping_path = max_path + '/' + project_name + '/province_city_mapping'\n",
    "if project_name == 'Gilead':\n",
    "    corp_mapping_path = max_path + \"/Gilead/FOR_MAX_standardization/corp_mapping\"\n",
    "    brand_mapping_path = max_path + \"/Gilead/FOR_MAX_standardization/brand_mapping\"\n",
    "if project_name == '奥鸿':    \n",
    "    raw_data_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/product_mapping_out\"\n",
    "if project_name == 'NHWA':\n",
    "    mofang_map_path = max_path + '/NHWA/FOR_delivery_files/恩华药品对照表' + out_dir[2:] + '.csv'\n",
    "    city_tier_1_path = max_path + '/NHWA/FOR_delivery_files/Other_MKT_Segment_Pfizer_0823.csv'\n",
    "if project_name == 'Astellas':\n",
    "    City_path = max_path + '/Astellas/FOR_delivery_files/ANS_新版省市mapping_City.csv'\n",
    "    Province_path = max_path + '/Astellas/FOR_delivery_files/ANS_新版省市mapping_Province.csv'\n",
    "if project_name == 'Servier':\n",
    "    ATC_molecule_path = max_path + '/Servier/FOR_delivery_files/ATC_molecule.csv'\n",
    "if project_name == 'XLT':\n",
    "    Region_map_path = max_path + '/XLT/FOR_delivery_files/Region_map.csv'\n",
    "    Province_City_map_path = max_path + '/XLT/FOR_delivery_files/信立泰省市匹配表.csv'\n",
    "    china_Region_map_path = max_path + '/XLT/FOR_delivery_files/账号权限省份Mapping.csv'\n",
    "    PTD_map_path = max_path + '/XLT/FOR_delivery_files/PTD_map.csv'\n",
    "if project_name == 'Pfizer':\n",
    "    GEO_CD_city_map_path = max_path + '/Pfizer/FOR_delivery_files/GEO_CD_city.csv'\n",
    "    change_min2_map_path = max_path + '/Pfizer/FOR_delivery_files/新老min2转换_2020.csv'\n",
    "    sifutuo_ratio_map_path = max_path + '/Pfizer/FOR_delivery_files/思福妥系数.csv'\n",
    "if project_name == 'Takeda':\n",
    "    ims_mapping_path  = max_path + '/Common_files/IMS_flat_files/' + out_dir + '/ims_mapping_' + out_dir + '.csv'\n",
    "        \n",
    "# 输出\n",
    "time_range = str(time_left) + '_' + str(time_right)\n",
    "out_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/\" + project_name + \"_max_delivery_\" + time_range + '.csv'\n",
    "if project_name == '奥鸿':\n",
    "    out2_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/\" + project_name + \"_max_delivery_\" + time_range + '_others.csv'\n",
    "if project_name == 'NHWA':\n",
    "    out2_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/\" + project_name + \"_max_delivery_\" + time_range + '_all.csv'\n",
    "if project_name == 'XLT':\n",
    "    out_noPTD_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/待清洗PTD系数.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "## 数据执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "### 一. 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ==========  数据执行  ============\n",
    "\n",
    "# ====  一. 函数定义  ====\n",
    "\n",
    "def deal_ID_length(df):\n",
    "    # ID不足7位的补足0到6位\n",
    "    # 国药诚信医院编码长度是7位数字，cpa医院编码是6位数字。\n",
    "    df = df.withColumn(\"ID\", df[\"ID\"].cast(StringType()))\n",
    "    # 去掉末尾的.0\n",
    "    df = df.withColumn(\"ID\", func.regexp_replace(\"ID\", \"\\\\.0\", \"\"))\n",
    "    df = df.withColumn(\"ID\", func.when(func.length(df.ID) < 7, func.lpad(df.ID, 6, \"0\")).otherwise(df.ID))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# NHWA\n",
    "if project_name == \"NHWA\":\n",
    "    @udf(StringType())\n",
    "    def for_ACC(name):\n",
    "        # ACC1/ACC2\n",
    "        if name in [\"咪达唑仑\", \"右美托咪定\"]:\n",
    "            newname = \"ACC1\"\n",
    "        elif name in [\"丙泊酚\", \"依托咪酯\",\"芬太尼\",\"瑞芬太尼\",\"舒芬太尼\"]:\n",
    "            newname = \"ACC2\"\n",
    "        else:\n",
    "            newname = \"-\"\n",
    "        return newname\n",
    "\n",
    "    @udf(StringType())\n",
    "    def for_region(pro, acc):\n",
    "        # 区域\n",
    "        if pro in [\"黑龙江\",\"吉林\",\"辽宁\"] and (acc == \"ACC1\"):\n",
    "            newname = \"东北区\"\n",
    "        elif pro in [\"北京\",\"天津\",\"上海\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华北一区\"\n",
    "        elif pro in [\"河北\",\"山西\",\"内蒙古\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华北二区\"\n",
    "        elif pro in [\"江苏\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华东一区\"\n",
    "        elif pro in [\"浙江\",\"福建\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华东二区\"\n",
    "        elif pro in [\"湖南\",\"湖北\",\"江西\"] and (acc == \"ACC1\"):\n",
    "            newname = \"中南区\"\n",
    "        elif pro in [\"广东\",\"广西\",\"海南\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华南区\"\n",
    "        elif pro in [\"重庆\",\"四川\"] and (acc == \"ACC1\"):\n",
    "            newname = \"西南一区\"\n",
    "        elif pro in [\"贵州\",\"云南\"] and (acc == \"ACC1\"):\n",
    "            newname = \"西南二区\"\n",
    "        elif pro in ['河南',\"陕西\",\"宁夏\",\"新疆\"] and (acc == \"ACC1\"):\n",
    "            newname = \"西北一区\"\n",
    "        elif pro in [\"安徽\",\"山东\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华东三区\"    \n",
    "        elif pro in [\"黑龙江\",\"吉林\",\"辽宁\"] and (acc == \"ACC2\"):\n",
    "            newname = \"东北区\"\n",
    "        elif pro in [\"北京\",\"天津\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华北一区\"\n",
    "        elif pro in [\"河北\",\"山西\",\"内蒙古\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华北二区\"\n",
    "        elif pro in [\"江苏\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华东一区\"\n",
    "        elif pro in [\"浙江\",\"福建\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华东二区\"\n",
    "        elif pro in [\"湖南\",\"湖北\",\"江西\"] and (acc == \"ACC2\"):\n",
    "            newname = \"中南区\"\n",
    "        elif pro in [\"广东\",\"广西\",\"海南\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华南区\"\n",
    "        elif pro in [\"重庆\",\"四川\"] and (acc == \"ACC2\"):\n",
    "            newname = \"西南一区\"\n",
    "        elif pro in [\"贵州\",\"云南\"] and (acc == \"ACC2\"):\n",
    "            newname = \"西南二区\"\n",
    "        elif pro in ['河南',\"陕西\",\"宁夏\",\"新疆\"] and (acc == \"ACC2\"):\n",
    "            newname = \"西北一区\"\n",
    "        elif pro in [\"安徽\",\"山东\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华东三区\"\n",
    "        elif pro in [\"上海\"] and (acc == \"ACC2\"):\n",
    "            newname = \"上海区\" \n",
    "        else:\n",
    "            newname = \"-\"\n",
    "        return newname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "### 二. 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ====  二. 数据准备  ====  \n",
    "\n",
    "# 产品信息，列名标准化\n",
    "product_map = spark.read.parquet(product_map_path)\n",
    "# a. 列名清洗统一\n",
    "# 有的min2结尾有空格与无空格的是两条不同的匹配\n",
    "#if project_name == \"Sanofi\" or project_name == \"AZ\":\n",
    "#    product_map = product_map.withColumnRenamed(product_map.columns[21], \"pfc\")\n",
    "#if project_name == \"Eisai\":\n",
    "#    product_map = product_map.withColumnRenamed(product_map.columns[22], \"pfc\")\n",
    "\n",
    "for i in product_map.columns:\n",
    "    if i in [\"标准通用名\", \"通用名_标准\", \"药品名称_标准\", \"S_Molecule_Name\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"通用名\")\n",
    "    if i in [\"min1_标准\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"min2\")\n",
    "    if i in [\"packcode\", \"Pack_ID\", \"Pack_Id\", \"PackID\", \"packid\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"pfc\")\n",
    "    if i in [\"商品名_标准\", \"S_Product_Name\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准商品名\")\n",
    "    if i in [\"剂型_标准\", \"Form_std\", \"S_Dosage\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准剂型\")\n",
    "    if i in [\"规格_标准\", \"Specifications_std\", \"药品规格_标准\", \"S_Pack\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准规格\")\n",
    "    if i in [\"包装数量2\", \"包装数量_标准\", \"Pack_Number_std\", \"S_PackNumber\", \"最小包装数量\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准包装数量\")\n",
    "    if i in [\"标准企业\", \"生产企业_标准\", \"Manufacturer_std\", \"S_CORPORATION\", \"标准生产厂家\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准生产企业\")\n",
    "    if i in [\"ROAD\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"Route\")\n",
    "if project_name == \"Janssen\" or project_name == \"NHWA\":\n",
    "    if \"标准剂型\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"剂型\", \"标准剂型\")\n",
    "    if \"标准规格\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"规格\", \"标准规格\")\n",
    "    if \"标准生产企业\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"生产企业\", \"标准生产企业\")\n",
    "    if \"标准包装数量\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"包装数量\", \"标准包装数量\")\n",
    "\n",
    "# b. min2处理\n",
    "product_map = product_map.withColumn(\"min2\", func.regexp_replace(\"min2\", \"&amp;\", \"&\")) \\\n",
    "                .withColumn(\"min2\", func.regexp_replace(\"min2\", \"&lt;\", \"<\")) \\\n",
    "                .withColumn(\"min2\", func.regexp_replace(\"min2\", \"&gt;\", \">\"))\n",
    "\n",
    "if 'Route' not in product_map.columns:\n",
    "    product_map = product_map.withColumn('Route', func.lit('-'))\n",
    "    \n",
    "# c. 列处理\n",
    "if project_name != 'Pfizer':\n",
    "    product_map = product_map.withColumn(\"pfc\", product_map[\"pfc\"].cast(IntegerType())) \\\n",
    "\n",
    "product_map = product_map.withColumn(\"标准包装数量\", product_map[\"标准包装数量\"].cast(IntegerType())) \\\n",
    "                    .withColumnRenamed(\"pfc\", \"PACK_ID\") \\\n",
    "                    .distinct()\n",
    "\n",
    "# d. pfc为0统一替换为null\n",
    "product_map = product_map.withColumn(\"PACK_ID\", func.when((col('PACK_ID') == 0) | (col('PACK_ID') == 'nan'), None) \\\n",
    "                                             .otherwise(col('PACK_ID'))).distinct()\n",
    "\n",
    "# e 选取需要的列\n",
    "if project_name == 'NHWA':\n",
    "    product_map = product_map \\\n",
    "                .withColumn('mofang_prod', func.concat(col('药品名称'), col('商品名'), col('剂型'),col('规格'), col('生产企业'))) \\\n",
    "                .withColumn('mofang_prod', func.regexp_replace(\"mofang_prod\", \" \", \"\")) \\\n",
    "                .withColumn('mofang_prod_2', func.concat(col('通用名'), col('标准商品名'), col('标准剂型'), col('标准规格'), col('标准生产企业'))) \\\n",
    "                .withColumn('mofang_prod_2', func.regexp_replace(\"mofang_prod_2\", \" \", \"\")) \\\n",
    "                .select(\"min1\", \"PACK_ID\", \"通用名\", \"标准商品名\", \"标准剂型\", \"标准规格\", \"标准包装数量\", \"标准生产企业\", 'Route', \n",
    "                       \"min2\", \"商品名+SKU\", \"毫克数\", \"mofang_prod\", \"mofang_prod_2\")\n",
    "elif project_name == 'Takeda':\n",
    "    product_map = product_map \\\n",
    "                .select(\"min1\", \"PACK_ID\", \"通用名\", \"标准商品名\", \"标准剂型\", \"标准规格\", \"标准包装数量\", \"标准生产企业\", 'Route', \"min2\", \n",
    "                       'Molecule_EN', 'Prd_desc', 'Form_EN', 'Size_EN', 'PckSize_Desc', 'Mnf_Desc') \n",
    "    \n",
    "else:\n",
    "    # 项目通用标准列\n",
    "    product_map = product_map \\\n",
    "                .select(\"min1\", \"PACK_ID\", \"通用名\", \"标准商品名\", \"标准剂型\", \"标准规格\", \"标准包装数量\", \"标准生产企业\", 'Route', \"min2\") \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "### 三. Max数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "##### 1. 提取交付数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =====  Max =====\n",
    "\n",
    "# 1. 读取交付数据\n",
    "if time_left//100 == time_right//100:\n",
    "    monthlist = range(time_left, time_right+1, 1)\n",
    "else:\n",
    "    monthlist = list(range(time_right//100*100+1, time_right+1, 1))\n",
    "    years=range(time_left//100, time_right//100, 1)\n",
    "    for each in years:\n",
    "        monthlist.extend(range(each*100+1, each*100+13, 1))\n",
    "        \n",
    "path_list = [max_standard_path + '/Date_copy=' + str(i) for i in monthlist]\n",
    "\n",
    "index = 0\n",
    "for eachpath in path_list:\n",
    "    df = spark.read.parquet(eachpath)\n",
    "    if index ==0:\n",
    "        data_standard = df\n",
    "    else:\n",
    "        data_standard = data_standard.union(df)\n",
    "    index += 1\n",
    "\n",
    "data_standard = data_standard.withColumn(\"Prod_Name\", func.regexp_replace(\"Prod_Name\", \"&amp;\", \"&\")) \\\n",
    "                            .withColumn(\"Prod_Name\", func.regexp_replace(\"Prod_Name\", \"&lt;\", \"<\")) \\\n",
    "                            .withColumn(\"Prod_Name\", func.regexp_replace(\"Prod_Name\", \"&gt;\", \">\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "##### 2. Sales，Units 处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Sales，Units 处理\n",
    "'''\n",
    "包装数量为空的是others， Sales 或者 Units 可以为0\n",
    "包装数量不为空的，Sales和Units只要有一列为0，那么都调整为0；Units先四舍五入为整数，然后变化的系数乘以Sales获得新的Sales\n",
    "Sales 保留两位小数\n",
    "负值调整为0\n",
    "去掉 Sales，Units 同时为0的行\n",
    "'''\n",
    "data_standard_0 = data_standard.withColumn(\"Predict_Sales\", col(\"Predict_Sales\").cast(DoubleType())) \\\n",
    "                        .withColumn(\"Predict_Unit\", col(\"Predict_Unit\").cast(DoubleType())) \\\n",
    "                        .fillna(0, [\"Predict_Sales\", \"Predict_Unit\"])\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"Units\", func.when((~col(\"标准包装数量\").isNull()) & (col('Predict_Unit') <= 0), func.lit(0)) \\\n",
    "                                                                .otherwise(func.round(col('Predict_Unit'), 0)))\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"p\", col('Units')/col('Predict_Unit'))\n",
    "data_standard_0 = data_standard_0.withColumn(\"p\", func.when((~col(\"标准包装数量\").isNull()) & (col(\"p\").isNull()), func.lit(0)) \\\n",
    "                                                    .otherwise(col('p')))\n",
    "data_standard_0 = data_standard_0.withColumn(\"p\", func.when((col(\"标准包装数量\").isNull()) & (col(\"p\").isNull()), func.lit(1)) \\\n",
    "                                                    .otherwise(col('p')))\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"Sales\", col('Predict_Sales') * col('p'))\n",
    "\n",
    "data_standard_0 = data_standard_0.withColumn(\"Sales\", func.round(col('Sales'), 2)) \\\n",
    "                            .withColumn(\"Units\", col(\"Units\").cast(IntegerType())) \\\n",
    "                            .drop(\"Predict_Unit\", \"Predict_Sales\", \"p\")\n",
    "# 负值调整为0\n",
    "data_standard_0 = data_standard_0.withColumn(\"Sales\", func.when(col('Sales') < 0 , func.lit(0)).otherwise(col('Sales'))) \\\n",
    "                                .withColumn(\"Units\", func.when(col('Sales') == 0, func.lit(0)).otherwise(col('Units')))\n",
    "\n",
    "# 去掉 Sales，Units 同时为0的行\n",
    "data_standard_1 = data_standard_0.where(col(\"标准包装数量\").isNull())\n",
    "data_standard_2 = data_standard_0.where((~col(\"标准包装数量\").isNull()) & (col('Sales') != 0) & (col('Units') != 0))\n",
    "\n",
    "data_standard_3 =  data_standard_1.union(data_standard_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 测试\n",
    "#data_standard_3 = data_standard.withColumnRenamed('Predict_Unit', 'Units') \\\n",
    "#                                .withColumnRenamed('Predict_Sales', 'Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "#### 3.信息匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 信息匹配\n",
    "if project_name == 'Pfizer':\n",
    "    # change_min2_map 新老min2转换\n",
    "    change_min2_map = spark.read.csv(change_min2_map_path, header=True)\n",
    "    change_min2_map = change_min2_map.select('min2_old', 'min2_new').distinct()\n",
    "        \n",
    "    data_standard_3 = data_standard_3.join(change_min2_map, data_standard_3.Prod_Name == change_min2_map.min2_old, \n",
    "                                                      how='left') \\\n",
    "                                    .withColumn('Prod_Name', func.when(~col('min2_new').isNull(), col('min2_new')) \\\n",
    "                                                                           .otherwise(col('Prod_Name')))\n",
    "    \n",
    "# 通用匹配产品信息    \n",
    "data_standard_map_info = data_standard_3.select(\"Province\", \"City\", \"Date\", \"Prod_Name\", \"Molecule\", \"PANEL\", \"DOI\",\n",
    "                                            \"Sales\", \"Units\")\n",
    "data_standard_map_info = data_standard_map_info.join(product_map.dropDuplicates(['min2']), \n",
    "                                                     data_standard_map_info.Prod_Name == product_map.min2, how='left')\n",
    "\n",
    "\n",
    "# Pfizer 多了一些匹配信息\n",
    "if project_name == 'Takeda':\n",
    "    # 匹配\n",
    "    ims_mapping = spark.read.csv(ims_mapping_path, header=True)\n",
    "    ims_mapping = ims_mapping.select('Pack_Id0', 'Mnf_Desc', 'MNF_TYPE').distinct() \\\n",
    "                            .withColumnRenamed('Pack_Id0', 'PACK_ID')\n",
    "    data_standard_map_info = data_standard_map_info.join(ims_mapping.select('Mnf_Desc','MNF_TYPE').dropDuplicates(['Mnf_Desc']), \n",
    "                                                         on='Mnf_Desc', how='left')\n",
    "    data_standard_map_info = data_standard_map_info.withColumn('MNF_TYPE', func.regexp_replace('MNF_TYPE', 'I|J', 'MNC')) \\\n",
    "                                                    .withColumn('MNF_TYPE', func.regexp_replace('MNF_TYPE', 'L', 'LOCAL'))\n",
    "    \n",
    "# Pfizer 多了一些匹配信息\n",
    "if project_name == 'Pfizer':\n",
    "    data_standard_map_info = data_standard_map_info.withColumn('City', func.regexp_replace('City', '市|地区', '')) \\\n",
    "                                                .withColumn('Date', func.concat_ws('M', func.substring(col('Date'), 0, 4), \n",
    "                                                                                   func.substring(col('Date'), 5, 2)))\n",
    "    \n",
    "    # 1.GEO_CD_city_map\n",
    "    GEO_CD_city_map = spark.read.csv(GEO_CD_city_map_path, header=True)\n",
    "    GEO_CD_city_map = GEO_CD_city_map.withColumn('City', func.regexp_replace('City', '地区', '')) \\\n",
    "                                    .select('City', 'GEO_CD').distinct()\n",
    "      \n",
    "    # 2.sifutuo_ratio_map\n",
    "    sifutuo_ratio_map = spark.read.csv(sifutuo_ratio_map_path, header=True)\n",
    "    sifutuo_ratio_map = sifutuo_ratio_map.select('Date', 'ratio').distinct()\n",
    "    \n",
    "    data_standard_map_info = data_standard_map_info.join(GEO_CD_city_map, on='City', how='left') \\\n",
    "                                                .join(sifutuo_ratio_map, on='Date', how='left')\n",
    "\n",
    "# XLT 多了一些匹配信息\n",
    "if project_name == 'XLT':        \n",
    "    # 1. 省市标准化\n",
    "    Province_City_map = spark.read.csv(Province_City_map_path, header=True)\n",
    "    data_standard_map_info = data_standard_map_info.join(Province_City_map.select('Servier_Province','XLT_Province').distinct(), \n",
    "                                                        data_standard_map_info.Province == Province_City_map.XLT_Province, how='left') \\\n",
    "                                           .join(Province_City_map.select('Servier_City','XLT_City').distinct(), \n",
    "                                                        data_standard_map_info.City == Province_City_map.Servier_City, how='left')\n",
    "    data_standard_map_info = data_standard_map_info.withColumn('Province', func.when(~col('Servier_Province').isNull(), col('Servier_Province')) \\\n",
    "                                                                               .otherwise(col('Province'))) \\\n",
    "                                                   .withColumn('City', func.when(~col('XLT_City').isNull(), col('XLT_City')) \\\n",
    "                                                                               .otherwise(col('City'))) \\\n",
    "                                                    .drop('Servier_Province','XLT_Province', 'Servier_City','XLT_City')\n",
    "    # 2. 匹配区域\n",
    "    # Region_map = spark.read.csv(Region_map_path, header=True)    \n",
    "    # Region_map = Region_map.withColumnRenamed('省份', 'Province') \\\n",
    "    #                        .select('Province', '区域').distinct()\n",
    "\n",
    "    china_Region_map = spark.read.csv(china_Region_map_path, header=True)\n",
    "    china_Region_map = china_Region_map.withColumnRenamed('省份', 'Province') \\\n",
    "                                        .select('南北中国', '区域','Province').distinct()\n",
    "    \n",
    "    # 3. PTD匹配\n",
    "    PTD_map = spark.read.csv(PTD_map_path, header=True)\n",
    "    PTD_map = PTD_map.select('商品名+SKU', 'PTD系数').distinct() \\\n",
    "                    .withColumnRenamed('商品名+SKU', 'Prod_Name')\n",
    "    \n",
    "    data_standard_map_info = data_standard_map_info.withColumn('Prod_Name', func.regexp_replace(\"Prod_Name\", \"\\\\|\", \"\")) \\\n",
    "                                                    .join(china_Region_map, on='Province', how='left') \\\n",
    "                                                    .join(PTD_map, on='Prod_Name', how='left')\n",
    "    \n",
    "    # 输出没匹配到PTD的条目\n",
    "    noPTD = data_standard_map_info.where(col('PTD系数').isNull()).select(\"Molecule\", \"标准商品名\", \"Prod_Name\", \"PTD系数\").distinct()\n",
    "    if noPTD.count() > 0:\n",
    "        noPTD = noPTD.repartition(1)\n",
    "        noPTD.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "            .mode(\"overwrite\").save(out_noPTD_path)\n",
    "        \n",
    "    \n",
    "# Servier 多了一些匹配信息\n",
    "if project_name == 'Servier':\n",
    "    ATC_molecule_map = spark.read.csv(ATC_molecule_path, header=True)\n",
    "    ATC_molecule_map = ATC_molecule_map.withColumnRenamed('S_Molecule.Name', '通用名') \\\n",
    "                                        .select('通用名', 'ATC3编码')\n",
    "    \n",
    "    data_standard_map_info = data_standard_map_info.join(ATC_molecule_map, on='通用名', how='left')\n",
    "    \n",
    "# Astellas 多了一些匹配信息\n",
    "if project_name == 'Astellas':\n",
    "    # 匹配标准化省市名称\n",
    "    City_map = spark.read.csv(City_path, header=True)\n",
    "    Province_map = spark.read.csv(Province_path, header=True)\n",
    "    data_standard_map_info = data_standard_map_info.join(City_map.dropDuplicates(['City']), on='City', how='left') \\\n",
    "                                                .join(Province_map.dropDuplicates(['Province']), on='Province', how='left')\n",
    "    \n",
    "    data_standard_map_info = data_standard_map_info.drop('City', 'Province') \\\n",
    "                                                .withColumnRenamed('标准_市', 'City') \\\n",
    "                                                .withColumnRenamed('标准_省', 'Province')\n",
    "    \n",
    "# NHWA 多了一些匹配信息\n",
    "if project_name == 'NHWA':  \n",
    "    # 魔方信息\n",
    "    mofang_map = spark.read.csv(mofang_map_path, header=True)\n",
    "    mofang_map = mofang_map.withColumn('mofang_prod', func.concat(col('药品名称'), col('商品名'), col('剂型'),\n",
    "                                                                   col('规格'), col('生产企业'))) \\\n",
    "                            .withColumn('mofang_prod', func.regexp_replace(\"mofang_prod\", \" \", \"\")) \\\n",
    "                            .join(product_map.select('mofang_prod', 'mofang_prod_2').dropDuplicates(['mofang_prod']), \n",
    "                                  on='mofang_prod', how='left') \\\n",
    "                            .select('mofang_prod_2', '药品索引').distinct()\n",
    "    # city_tier 城市\n",
    "    city_tier_1 = spark.read.csv(city_tier_1_path, header=True)\n",
    "    city_tier_1 = city_tier_1.select('City Tier 2010', 'Prefecture').distinct() \\\n",
    "                            .withColumn('City Tier 2010', city_tier_1['City Tier 2010'].cast(IntegerType())) \\\n",
    "                            .withColumnRenamed('Prefecture', 'City') \\\n",
    "                            .withColumnRenamed('City Tier 2010', 'City_Tier')\n",
    "    \n",
    "    # join\n",
    "    data_standard_map_info = data_standard_map_info.join(mofang_map, on='mofang_prod_2', how='left') \\\n",
    "                                                .join(city_tier_1, on='City', how='left')\n",
    "    \n",
    "    City_list_5 = [\"省直辖县级行政单位\",\"甘南州\",\"毕节市\",\"吐鲁番市\",\"海东市\",\"自治区直辖县级行政单位\",\"哈密市\",\"铜仁市\",\"日喀则市\",\"昌都市\"]\n",
    "    data_standard_map_info = data_standard_map_info.withColumn('City_Tier', \n",
    "                                                            func.when(col('City').isin(City_list_5), func.lit(5)).otherwise(col('City_Tier'))) \\\n",
    "                                                    .withColumn('City_Tier', \n",
    "                                                            func.when(col('City').isin(\"襄阳市\"), func.lit(4)).otherwise(col('City_Tier')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "#### 4.groupby 以及列名重命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 通用\n",
    "if project_name != 'NHWA':\n",
    "    # groupby 计算\n",
    "    if project_name == 'Servier':\n",
    "        max_standard_delivery_out = data_standard_map_info.groupby([\"Date\", \"Province\", \"City\", \"Molecule\", \"标准商品名\", \"标准剂型\", \"标准规格\", \n",
    "                                                       \"标准包装数量\", \"标准生产企业\", \"Prod_Name\", \"DOI\", \"Route\", \"ATC3编码\"]) \\\n",
    "                                            .agg(func.sum('Sales').alias('金额'), func.sum('Units').alias('数量'))\n",
    "    elif project_name == 'XLT':\n",
    "        max_standard_delivery_out = data_standard_map_info.groupby([\"Date\", \"Province\", \"City\", \"Molecule\", \"标准商品名\", \"标准剂型\", \"标准规格\", \n",
    "                                                       \"标准包装数量\", \"标准生产企业\", \"Prod_Name\",\n",
    "                                                        \"区域\", \"南北中国\", \"PTD系数\"]) \\\n",
    "                                            .agg(func.sum('Sales').alias('金额'), func.sum('Units').alias('数量'))\n",
    "    elif project_name == 'Pfizer':\n",
    "        max_standard_delivery_out = data_standard_map_info.groupby([\"Date\", \"Province\", \"City\", \"Molecule\", \"标准商品名\", \"标准剂型\", \"标准规格\", \n",
    "                                                       \"标准包装数量\", \"标准生产企业\", \"Prod_Name\",\n",
    "                                                        \"ratio\", \"GEO_CD\", \"PACK_ID\"]) \\\n",
    "                                            .agg(func.sum('Sales').alias('金额'), func.sum('Units').alias('数量'))\n",
    "    elif project_name == 'Takeda':\n",
    "        max_standard_delivery_out = data_standard_map_info.groupby([\"Date\", \"Province\", \n",
    "                                                        \"Molecule\", \"标准商品名\", \"标准剂型\", \"标准规格\", \n",
    "                                                       \"标准包装数量\", \"标准生产企业\", \"Prod_Name\", \"PACK_ID\", \n",
    "                                                        \"Molecule_EN\", \"Prd_desc\", \"Form_EN\", \"Size_EN\", \"PckSize_Desc\", \"Mnf_Desc\", \"MNF_TYPE\"]) \\\n",
    "                                            .agg(func.sum('Sales').alias('金额'), func.sum('Units').alias('数量'))\n",
    "        \n",
    "    else:\n",
    "        max_standard_delivery_out = data_standard_map_info.groupby([\"Date\", \"Province\", \"City\", \"Molecule\", \"标准商品名\", \"标准剂型\", \"标准规格\", \n",
    "                                                       \"标准包装数量\", \"标准生产企业\", \"Prod_Name\", \"DOI\", \"Route\"]) \\\n",
    "                                            .agg(func.sum('Sales').alias('金额'), func.sum('Units').alias('数量'))\n",
    "\n",
    "    # 列名重命名\n",
    "    if project_name == 'Servier':\n",
    "        rename_list = {'Date':'Period', 'City':'City', 'Province':'Province', \n",
    "                       'Molecule':'Molecule_Name', '标准商品名':'Product_Name', \n",
    "                      '标准剂型':'Dosage', '标准规格':'Pack', '标准包装数量':'Pack_Number', '标准生产企业':'manufacturer',\n",
    "                      'DOI':'Market', '金额':'金额', '数量':'最小制剂单位数量', \n",
    "                        'Prod_Name':'Prod_Name', 'Route':'ROAD'}\n",
    "    \n",
    "    elif project_name == 'Pfizer':\n",
    "        rename_list = {'Date':'Period_Code', 'City':'城市', 'Province':'省份', \n",
    "                       'Molecule':'通用名', '标准商品名':'商品名', \n",
    "                      '标准剂型':'剂型', '标准规格':'规格', '标准包装数量':'包装数量', '标准生产企业':'生产企业',\n",
    "                       '金额':'LC', '数量':'SU', \n",
    "                        \"PACK_ID\":\"Pack_ID\", \"GEO_CD\":'Geography_id'}\n",
    "        \n",
    "    elif project_name == 'XLT':\n",
    "        rename_list = {'Date':'Date', 'City':'城市', 'Province':'省份', \n",
    "                       'Molecule':'通用名', '标准商品名':'商品名', \n",
    "                      '标准剂型':'剂型', '标准规格':'规格', '标准包装数量':'包装数量', '标准生产企业':'生产企业',\n",
    "                       '金额':'销售金额', '数量':'销售数量(片)', \n",
    "                        'Prod_Name':'商品名+SKU'}\n",
    "        \n",
    "    elif project_name == 'Astellas':\n",
    "        rename_list = {'Date':'YearMonth', 'City':'City', 'Province':'Province', \n",
    "                       'Molecule':'Molecule_CN', '标准商品名':'BrandName', \n",
    "                      '标准剂型':'Formulation', '标准规格':'Specification', '标准包装数量':'PackageNo', '标准生产企业':'Manufacture',\n",
    "                      'DOI':'MarketName_CN', '金额':'Predicted_Sales', '数量':'Predicted_Units'}\n",
    "        \n",
    "    elif project_name == 'Takeda':\n",
    "        rename_list = {'Province':'省份', \n",
    "                       'Molecule_EN':'通用名', 'Prd_desc':'商品名', \n",
    "                      'Form_EN':'剂型', 'Size_EN':'规格', 'PckSize_Desc':'包装数量', 'Mnf_Desc':'生产企业'}\n",
    "    else:\n",
    "        # 通用列名\n",
    "        rename_list = {'Date':'年月', 'City':'城市', 'Province':'省份', \n",
    "                       'Molecule':'通用名', '标准商品名':'商品名', \n",
    "                      '标准剂型':'剂型', '标准规格':'规格', '标准包装数量':'包装数量', '标准生产企业':'生产企业',\n",
    "                      'DOI':'市场名', 'Route':'给药途径'}\n",
    "        \n",
    "    for old_name, newname in rename_list.items():\n",
    "        max_standard_delivery_out = max_standard_delivery_out.withColumnRenamed(old_name, newname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %%\n",
    "#### 5.最终交付处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'Takeda':\n",
    "    # 城市名修改\n",
    "    @udf(StringType())\n",
    "    def change_Q(date):\n",
    "        if date[4:6] in ['01', '02', '03']:\n",
    "            datenew = date[0:4] + 'Q1'\n",
    "        elif date[4:6] in ['04', '05', '06']:\n",
    "            datenew = date[0:4] + 'Q2'\n",
    "        elif date[4:6] in ['07', '08', '09']:\n",
    "            datenew = date[0:4] + 'Q3'\n",
    "        elif date[4:6] in ['10', '11', '12']:\n",
    "            datenew = date[0:4] + 'Q4'\n",
    "        return datenew\n",
    "    \n",
    "    df1 = max_standard_delivery_out.withColumn('季度', change_Q(col('Date').cast(StringType()))) \\\n",
    "                                .withColumnRenamed('金额', '金额(元)') \\\n",
    "                                .withColumnRenamed('数量', '数量(支/片)')\n",
    "    \n",
    "    out = df1.select('季度', '省份', \"通用名\", \"商品名\", \"剂型\", \"规格\", \"生产企业\", \"MNF_TYPE\", \"包装数量\", \"金额(元)\", \"数量(支/片)\")\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'Pfizer':\n",
    "    df1 = max_standard_delivery_out.withColumn('UN', func.round(col('SU')/col('包装数量'), 0)) \\\n",
    "                                .groupby('Period_Code', 'Geography_id', 'Pack_ID', 'ratio') \\\n",
    "                                .agg(func.sum('LC').alias('LC'), func.sum('SU').alias('SU'), func.sum('UN').alias('UN'))\n",
    "    \n",
    "    df1 = df1.withColumn('LCD', func.lit(0)) \\\n",
    "            .withColumn('CU', func.lit(0)) \\\n",
    "            .withColumn('Channel_id', func.lit('P00'))\n",
    "    \n",
    "    # 调整思福妥\n",
    "    df_sifutuo = df1.where(col('Pack_ID') == '9733702')\n",
    "    df_sifutuo = df_sifutuo.withColumn('LC', func.round(col('LC') * col('ratio'), 2)) \\\n",
    "                            .withColumn('SU', func.round(col('SU') * col('ratio'), 0)) \\\n",
    "                            .withColumn('UN', func.round(col('UN') * col('ratio'), 0))\n",
    "    \n",
    "    df_others = df1.where( col('Pack_ID') != '9733702')\n",
    "    \n",
    "    df_all = df_others.union(df_sifutuo.select(df_others.columns))\n",
    "    \n",
    "    # 去掉一些条目\n",
    "    out = df_all.where(~col('Pack_ID').isNull()).where(~col('Geography_id').isNull()) \\\n",
    "                .where(~col('Geography_id').isin('ROC')) \\\n",
    "                .drop('ratio')\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "            .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'XLT':\n",
    "    df1 = max_standard_delivery_out.withColumn('市场', func.lit('高血压市场')) \\\n",
    "                                    .withColumn('年', func.substring(col('Date'), 0, 4).cast(IntegerType())) \\\n",
    "                                    .withColumn('月', func.substring(col('Date'), 5, 2).cast(IntegerType())) \\\n",
    "                                    .withColumn('销售数量(盒)', col('销售数量(片)')/col('包装数量')) \\\n",
    "                                    .withColumn('销售数量(盒)', func.round(col('销售数量(盒)'), 0).cast(IntegerType()))\n",
    "    \n",
    "    df2 = df1.where(col('商品名') != 'Others') \\\n",
    "            .withColumn('区域', func.when(col('区域').isin('华东1区'), func.lit('华东区')).otherwise(col('区域'))) \\\n",
    "            .withColumn('区域', func.when(col('区域').isin('华东2区'), func.lit('华中区')).otherwise(col('区域')))\n",
    "    \n",
    "    out = df2.withColumn('商品名', func.when(col('商品名') == col('通用名'), func.concat_ws('+', col('通用名'), col('生产企业'))) \\\n",
    "                                    .otherwise(col('商品名'))) \\\n",
    "            .drop('生产企业')\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'Servier':\n",
    "    df1 = max_standard_delivery_out.withColumn('Prod_Name', func.regexp_replace('Prod_Name', 'NA', '')) \\\n",
    "                                .withColumn('Prod_Name', func.regexp_replace('Prod_Name', '分散片', '片剂'))\n",
    "    \n",
    "    df1 = df1.withColumn('Product_Name', func.when(col('Product_Name') == '亚旭', func.lit('曲美他嗪—远大医药')).otherwise(col('Product_Name')))\n",
    "    \n",
    "    @udf(StringType())\n",
    "    def for_MarketValue(market, molname, ATC, sales):\n",
    "        c07 = ['比索洛尔', '美托洛尔', '普萘洛尔', '卡维地洛', '阿替洛尔', '阿罗洛尔', '拉贝洛尔', '索他洛尔', '塞利洛尔']\n",
    "        c08 = ['氨氯地平', '硝苯地平', '左旋氨氯地平', '非洛地平', '西尼地平', '尼卡地平', '尼群地平', '拉西地平', \n",
    "               '贝尼地平', '乐卡地平', '马尼地平', '阿折地平']\n",
    "        if market == 'IHD':\n",
    "            if molname in c07:\n",
    "                value = sales * 0.25\n",
    "            elif molname in c08:\n",
    "                value = sales * 0.2\n",
    "            else:\n",
    "                value = sales\n",
    "        elif market == 'CHF':\n",
    "            if ATC in ['C01A']:\n",
    "                value = sales * 0.5\n",
    "            elif ATC in ['C03A']:\n",
    "                value = sales * 0.2\n",
    "            elif molname in ['卡维地洛', '卡替洛尔']:\n",
    "                value = sales * 0.06\n",
    "            else:\n",
    "                value = sales\n",
    "        else:\n",
    "            value = sales\n",
    "        return value\n",
    "    \n",
    "    all_result = df1.withColumn('MarketValue', for_MarketValue(col('Market'), col('Molecule_Name'), col('ATC3编码'), col('金额'))) \\\n",
    "            .where( ~((col('Molecule_Name') == '卡维地洛') & (col('Market') == 'IHD')) )\n",
    "    \n",
    "    # [1] \"贝那普利\"      \"福辛普利\"      \"卡托普利\"      \"赖诺普利\"      \"雷米普利\"     \n",
    "    # [6] \"咪达普利\"      \"培哚普利\"      \"依那普利\"      \"依那普利/叶酸\"\n",
    "    PLAIN_s = all_result.where(col('ATC3编码') == 'C09A') \\\n",
    "                .withColumn('MarketValue', col('金额') * 0.04) \\\n",
    "                .withColumn('Market', func.lit('CHF'))\n",
    "    # 没有卡维地洛\n",
    "    CHF_s = all_result.where(col('ATC3编码') == 'C07A').where(col('Market') == 'IHD') \\\n",
    "                .withColumn('MarketValue', col('金额') * 0.06) \\\n",
    "                .withColumn('Market', func.lit('CHF')) \n",
    "    # 只卡维地洛\n",
    "    IHD_s = all_result.where(col('ATC3编码') == 'C07A').where(col('Market') == 'CHF') \\\n",
    "                .withColumn('MarketValue', col('金额') * 0.25) \\\n",
    "                .withColumn('Market', func.lit('IHD'))\n",
    "    \n",
    "    all_result_f = all_result.union(PLAIN_s).union(CHF_s).union(IHD_s)\n",
    "    all_result_f = all_result_f.where( (col('Molecule_Name').isin(['利拉鲁肽','艾塞那肽'])) | (col('ROAD').isin(['口服','口腔给药'])) | \n",
    "                                       (col('Market').isin(['CHF','ALVENOR'])) )\n",
    "    \n",
    "    std_names = ['Period', 'Province', 'City', 'Molecule Name', 'ATC3编码', 'Product Name', \n",
    "               'manufacturer', 'Pack', 'Pack Number', 'Dosage', 'ROAD', '金额', \n",
    "               '最小制剂单位数量', 'Market', 'MarketValue']\n",
    "    \n",
    "    out = all_result_f.toDF(*(re.sub(r'[\\_\\s]+', ' ', c) for c in all_result_f.columns)) \\\n",
    "                    .select(std_names)\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "            .mode(\"overwrite\").save(out_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name in ['贝达', '神州', '康哲', '京新']:\n",
    "    out = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                       \"包装数量\", \"生产企业\", \"金额\", \"数量\")    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == '奥鸿':\n",
    "    df = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"Prod_Name\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "\n",
    "    province_city_mapping = spark.read.parquet(province_city_mapping_path)\n",
    "    province_city_mapping = deal_ID_length(province_city_mapping)\n",
    "    province_city_mapping = province_city_mapping.select('ID', 'Province', 'City').distinct()\n",
    "\n",
    "    raw_data = spark.read.parquet(raw_data_path)\n",
    "    raw_data = deal_ID_length(raw_data)\n",
    "    raw_data_info = raw_data.where((col('year_month') >= time_left) & (col('year_month') <= time_right)) \\\n",
    "                        .drop('Province', 'City') \\\n",
    "                        .join(province_city_mapping, on='ID', how='left') \\\n",
    "                        .select('year_month', 'Province', 'min2') \\\n",
    "                        .withColumn('f_raw', func.concat_ws('+', col('year_month'), col('Province'), col('min2'))) \\\n",
    "                        .select('f_raw').distinct()\n",
    "    ## 这四个省样本量不足 删掉邦亭，其他省取样本有的所有产品\n",
    "    province_delete = ['甘肃省','广西壮族自治区','青海省','西藏自治区']\n",
    "\n",
    "    df2 = df.withColumn('f_max', func.concat_ws('+', col('年月'), col('省份'), col('Prod_Name')))\n",
    "    df3 = df2.join(raw_data_info, df2.f_max == raw_data_info.f_raw, how='left')\n",
    "    df4 = df3.withColumn('delete', func.when(~(col('f_raw').isNull()) | (col('省份').isin(province_delete) & col('Prod_Name').contains('邦亭')), \n",
    "                                              func.lit(0)).otherwise(func.lit(1)))\n",
    "\n",
    "    out1 = df4.where(col('delete') == 0).drop('f_raw', 'f_max', 'delete')\n",
    "    out2 = df4.where(col('delete') == 1).drop('f_raw', 'f_max', 'delete')\n",
    "    \n",
    "    out1 = out1.repartition(1)\n",
    "    out1.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)\n",
    "    \n",
    "    out2 = out2.repartition(1)\n",
    "    out2.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == '海坤':\n",
    "    out = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "    # 城市名修改\n",
    "    @udf(StringType())\n",
    "    def city_change(name):\n",
    "        # 城市名统一\n",
    "        dict = {\"毕节市\":\"毕节地区\", \"哈密市\":\"哈密地区\", \"日喀则市\":\"日喀则地区\", \"楚雄彝族自治州\":\"楚雄市\"}\n",
    "        if name in dict.keys():\n",
    "            newname = dict[name]\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    out = out.withColumn('城市', city_change(col('城市')))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == '汇宇':\n",
    "    out = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "    out = out.where(~col('通用名').isin('多西他赛','培美曲塞'))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'Tide':\n",
    "    out = max_standard_delivery_out.select(\"市场名\", \"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "    # 城市名修改\n",
    "    @udf(StringType())\n",
    "    def city_change(name):\n",
    "        # 城市名统一\n",
    "        dict = {\"毕节市\":\"毕节地区\", \"哈密市\":\"哈密地区\", \"日喀则市\":\"日喀则地区\", \"楚雄彝族自治州\":\"楚雄市\"}\n",
    "        if name in dict.keys():\n",
    "            newname = dict[name]\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    @udf(StringType())\n",
    "    def province_change(name):\n",
    "        # 城市名统一\n",
    "        dict = {\"内蒙\":\"内蒙古\", \"黑龙\":\"黑龙江\"}\n",
    "        if name in dict.keys():\n",
    "            newname = dict[name]\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    out = out.withColumn('城市', city_change(col('城市'))) \\\n",
    "            .withColumn('省份', func.substring(col('省份'), 0, 2)) \\\n",
    "            .withColumn('省份', province_change(col('省份'))) \\\n",
    "            .withColumn('市场名', func.when((col('通用名') == '氟比洛芬') & (col('剂型') == '注射剂'), func.lit('凯纷')).otherwise(col('市场名')))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'Gilead':\n",
    "    df = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                           \"包装数量\", \"生产企业\", \"金额\", \"数量\", \"给药途径\")\n",
    "    df = df.withColumnRenamed('金额', '销售金额') \\\n",
    "            .withColumnRenamed('数量', '销售数量（最小单位:片支）') \\\n",
    "    \n",
    "    corp_mapping = spark.read.parquet(corp_mapping_path)\n",
    "    corp_mapping = corp_mapping.where(~col('Corp_STD_EN').isNull()) \\\n",
    "                                .select(corp_mapping.columns[0:3]).distinct() \\\n",
    "                                .withColumnRenamed('Corporation', '生产企业')\n",
    "    \n",
    "    brand_mapping = spark.read.parquet(brand_mapping_path)\n",
    "    brand_mapping = brand_mapping.where(~col('Molecue_STD_EN').isNull()) \\\n",
    "                                .select(brand_mapping.columns[1:8]).distinct() \\\n",
    "                                .withColumnRenamed('DrugName_Molecue', '通用名') \\\n",
    "                                .withColumnRenamed('ProductName', '商品名') \\\n",
    "                                .withColumnRenamed('Corp_CN', '生产企业')\n",
    "    \n",
    "    df2 = df.join(brand_mapping, on=['通用名', '商品名', '生产企业'], how='left') \\\n",
    "           .join(corp_mapping, on=['生产企业'], how='left')\n",
    "    \n",
    "    @udf(StringType())\n",
    "    def Corp_change(name, corp, brand, std):\n",
    "        # 公司名修改    \n",
    "        if corp == '株洲千金药业股份有限公司' and brand == '艾普丁':\n",
    "            if std == 'EN':\n",
    "                newname = 'HN.QIANJIN XIELI'\n",
    "            elif std == 'CN':\n",
    "                newname = '湖南千金协力药业有限公司'\n",
    "        elif corp == '株洲千金药业股份有限公司' and (brand in ['健甘灵','乾力安']):\n",
    "            if std == 'EN':\n",
    "                newname = 'QIANJINXIANGJIANG'\n",
    "            elif std == 'CN':\n",
    "                newname = '湖南千金湘江药业股份有限公司'\n",
    "        else:\n",
    "            newname = name\n",
    "        return newname\n",
    "    \n",
    "    out = df2.withColumn('Corp_STD_EN', Corp_change(col('Corp_STD_EN'), col('生产企业'), col('商品名'), func.lit('EN'))) \\\n",
    "            .withColumn('Corp_STD_CN', Corp_change(col('Corp_STD_CN'), col('生产企业'), col('商品名'), func.lit('CN')))\n",
    "    \n",
    "    out = out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \"包装数量\", \"生产企业\", \"销售金额\", \"销售数量（最小单位:片支）\", \n",
    "                     \"给药途径\", \"Molecue_STD_EN\", \"Molecue_STD_CN\", \"Brand_STD_EN\", \"Brand_STD_CN\", \"Corp_STD_EN\", \"Corp_STD_CN\")\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'Qilu':\n",
    "    out = max_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                       \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "    out = out.where( ~ ((col('通用名')=='替诺福韦二吡呋酯') & (col('省份')=='西藏')))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'NHWA':\n",
    "    df = data_standard_map_info.withColumnRenamed('Date', '时间') \\\n",
    "                                                    .withColumnRenamed('Province', '省份') \\\n",
    "                                                    .withColumnRenamed('City', '城市') \\\n",
    "                                                    .withColumnRenamed('Molecule', '分子名') \\\n",
    "                                                    .withColumnRenamed('标准商品名', '商品名_标准') \\\n",
    "                                                    .withColumnRenamed('标准剂型', '剂型') \\\n",
    "                                                    .withColumnRenamed('标准规格', '规格') \\\n",
    "                                                    .withColumnRenamed('标准包装数量', '包装数量') \\\n",
    "                                                    .withColumnRenamed('标准生产企业', '生产企业_标准') \\\n",
    "                                                    .withColumnRenamed('DOI', '市场名') \\\n",
    "                                                    .withColumnRenamed('City_Tier_2010', '给药途径') \\\n",
    "                                                    .withColumnRenamed('Sales', '销售金额') \\\n",
    "                                                    .withColumnRenamed('Units', '销售数量')\n",
    "\n",
    "    df2 = df.withColumn('省', func.regexp_replace(\"省份\", \"省|回族自治区|壮族自治区|维吾尔族自治区|维吾尔自治区|自治区|市\", \"\"))\n",
    "    # 根据分子名定义ACC1/ACC2\n",
    "    df2 = df2.withColumn('ACC1/ACC2', for_ACC(col('分子名')))\n",
    "    # 根据省和ACC1/ACC2定义区域\n",
    "    df2 = df2.withColumn('区域', for_region(col('省'), col('ACC1/ACC2')))\n",
    "\n",
    "    df2 = df2.withColumn('市场I', func.lit(\"麻醉市场\")) \\\n",
    "                .withColumn('市场II', func.lit(None).cast(StringType())) \\\n",
    "                .withColumn('市场III', func.lit(None).cast(StringType())) \\\n",
    "                .withColumn('商品名_标准', func.when(col('商品名_标准') == \"乐维伽\", func.lit(\"右美宁\")).otherwise(col('商品名_标准'))) \\\n",
    "                .fillna(0, '毫克数') \\\n",
    "                .withColumn('销售毫克数', col('销售数量')*col('毫克数')) \\\n",
    "                .withColumn('power', func.concat(col('分子名'), col('区域'))) \\\n",
    "                .withColumn('年', func.substring(col('时间'), 0, 4)) \\\n",
    "                .withColumn('月', func.substring(col('时间'), 5, 2))\n",
    "\n",
    "    out = df2.groupby([\"时间\", \"城市\", \"min2\", \"商品名+SKU\", \"商品名_标准\", \"生产企业_标准\", \"年\", \"月\", \"省份\", \"City_Tier\",\n",
    "                    \"市场I\", \"区域\", \"分子名\", \"ACC1/ACC2\", \"power\", \"规格\", \"剂型\", \"包装数量\", \"药品索引\"]) \\\n",
    "            .agg(func.sum('销售数量').alias('销售数量'), func.sum('销售金额').alias('销售金额'), func.sum('销售毫克数').alias('销售毫克数'))\n",
    "\n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)\n",
    "\n",
    "    out2 = out.groupby([\"商品名+SKU\", \"商品名_标准\",\"年\", \"月\", \"市场I\", \"区域\", \"分子名\", \"规格\", \"剂型\"]) \\\n",
    "            .agg(func.sum('销售数量').alias('销售数量'), func.sum('销售金额').alias('销售金额'), func.sum('销售毫克数').alias('销售毫克数'))\n",
    " \n",
    "    out2 = out2.repartition(1)\n",
    "    out2.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if project_name == 'Astellas':\n",
    "    df = max_standard_delivery_out.select(\"YearMonth\", \"Province\", \"City\", \"Molecule_CN\", \"BrandName\", \"Formulation\", \"Specification\", \n",
    "                                                       \"PackageNo\", \"Manufacture\", 'MarketName_CN', \"Predicted_Sales\", \"Predicted_Units\")\n",
    "    \n",
    "    df1 = df.withColumn('BrandName', func.when((col('BrandName') == '哈乐') & (col('Formulation') == '片剂') & (col('PackageNo') == 14), \n",
    "                                             func.lit('新哈乐')).otherwise(col('BrandName'))) \\\n",
    "            .withColumn('BrandName', func.when((col('BrandName') == '新哈乐') & (col('Formulation') == '片剂') & (col('PackageNo') == 10), \n",
    "                                             func.lit('哈乐')).otherwise(col('BrandName')))\n",
    "    \n",
    "    df2 = df1.where( ~( (~col('Formulation').isin('粉针剂', '注射剂')) & (col('MarketName_CN').isin('米开民市场', '佩尔市场')) ) & \n",
    "                     ~( (col('Formulation').isin('粉针剂', '注射剂', '滴眼剂','气雾剂','喷雾剂')) & (col('MarketName_CN').isin('阿洛刻市场')) ) &\n",
    "                    ~( (col('Formulation').isin('滴眼剂')) & (col('MarketName_CN').isin('普乐可复市场')) ) & \n",
    "                    ~( col('BrandName').isin('保法止')) )\n",
    "    \n",
    "    df3 = df2.where(~col('BrandName').isin(\"倍他司汀\", \"阿魏酰γ-丁二胺/植物生长素\", \"丙磺舒\", \"复方别嘌醇\"))\n",
    "    \n",
    "    df4 = df3.where(~( (~col('BrandName').isin('可多华', '保列治', '高特灵', '贝可', '得妥', '宁通', '舍尼亭', '托特罗定')) & \n",
    "                      (col('Molecule_CN').isin('多沙唑嗪', '特拉唑嗪', '非那雄胺', '托特罗定')) ))\n",
    "    \n",
    "    df5 = df4.withColumn('MarketName_CN', func.when(col('MarketName_CN') == '白血病市场', func.lit('急性髓系白血病市场')) \\\n",
    "                                             .otherwise(col('MarketName_CN')))\n",
    "    \n",
    "    out = df5.withColumn('Quarter', func.concat(func.substring('YearMonth', 0, 4), func.lit('Q') ,func.ceil(func.substring('YearMonth', 5, 2)/3) ))\n",
    "    \n",
    "    out = out.repartition(1)\n",
    "    out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#out.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#out.agg(func.sum('金额'), func.sum('最小制剂单位数量')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#out.agg(*[func.count(func.when(func.isnull(c), c)).alias(c) for c in out.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#out.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
