{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phcli Jupyter Template\n",
    "# \n",
    "# 使用手册：\n",
    "# 1. 请将全局变量定义在第一个输入区内\n",
    "# 2. Phcli 会自动在第二个输入区初始化 Spark Session\n",
    "# 3. 所有 print 会在 phcli maxauto dag 后自动转为 logger.debug() 方法\n",
    "# 4. 请在第三个输入区开始编码，phcli maxauto dag 后会全部归类为一个方法\n",
    "\n",
    "\n",
    "# Config defined in here\n",
    "\n",
    "############## == config == ###################\n",
    "job_name = \"delivery\"\n",
    "job_runtime = \"python3\"\n",
    "job_command = \"submit\"\n",
    "job_timeout = 720.0\n",
    "############## == config == ###################\n",
    "\n",
    "\n",
    "# Variables defined in here\n",
    "\n",
    "############## == input args == ###################\n",
    "project_name = \"Empty\"\n",
    "time_left = \"Empty\"\n",
    "time_right = \"Empty\"\n",
    "out_dir = \"Empty\"\n",
    "extract_path = \"s3a://ph-stream/common/public/max_result/0.0.5/rawdata_standard\"\n",
    "max_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "############## == input args == ###################\n",
    "\n",
    "############## == output args == ###################\n",
    "c = 'abc'\n",
    "d = 'def'\n",
    "############## == output args == ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# ENV\n",
    "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/local/spark\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"AKIAWPBDTVEAEU44ZAGT\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"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\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"cn-northwest-1\"\n",
    "\n",
    "# prepare\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"ywyuan write Raw_delivery in jupyter using python3\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .config('spark.sql.codegen.wholeStage', False) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "if access_key:\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.cn-northwest-1.amazonaws.com.cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from phcli.ph_logs.ph_logs import phs3logger\n",
    "# from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import functions as func\n",
    "import os\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, col, udf\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "project_name = \"XLT\"\n",
    "time_left = \"202001\"\n",
    "time_right = \"202012\"\n",
    "out_dir = \"202012\"\n",
    "extract_path = \"s3a://ph-stream/common/public/max_result/0.0.5/rawdata_standard\"\n",
    "max_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 样本数据交付"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入\n",
    "time_left = int(time_left)\n",
    "time_right = int(time_right)\n",
    "\n",
    "CPA_GYC_hospital_map_path = max_path + \"/Common_files/CPA_GYC_hospital_map\"\n",
    "HAIHONG_hospital_map_path = max_path + \"/Common_files/HAIHONG_hospital_map\"\n",
    "\n",
    "product_map_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/prod_mapping\"\n",
    "province_city_mapping_path = max_path + '/' + project_name + '/province_city_mapping'\n",
    "cpa_pha_mapping_path = max_path + '/' + project_name + '/cpa_pha_mapping'\n",
    "raw_standard_path = extract_path + \"/\" + project_name + \"_rawdata_standard\"\n",
    "\n",
    "if project_name == 'NHWA':\n",
    "    mofang_map_path = max_path + '/NHWA/FOR_delivery_files/恩华药品对照表' + out_dir[2:] + '.csv'\n",
    "    city_tier_path = max_path + '/NHWA/FOR_delivery_files/城市级别匹配.csv'\n",
    "    CPA_GYC_hospital_map_old_path = max_path + \"/Common_files/CPA_GYC_hospital_map_old.csv\"\n",
    "if project_name == 'XLT':\n",
    "    Hospital_id_map_path = max_path + '/XLT/FOR_delivery_files/Hospital_id_map.csv'\n",
    "    # Region_map_path = max_path + '/XLT/FOR_delivery_files/Region_map.csv'\n",
    "    Province_City_map_path = max_path + '/XLT/FOR_delivery_files/信立泰省市匹配表.csv'\n",
    "    china_Region_map_path = max_path + '/XLT/FOR_delivery_files/账号权限省份Mapping.csv'\n",
    "    PTD_map_path = max_path + '/XLT/FOR_delivery_files/PTD_map.csv'   \n",
    "\n",
    "# 输出\n",
    "time_range = str(time_left) + '_' + str(time_right)\n",
    "out_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/\" + project_name + \"_raw_delivery_\" + time_range + '.csv'\n",
    "if project_name == 'XLT':\n",
    "    out_noPTD_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/待清洗PTD系数.csv\"\n",
    "# tmp_path = max_path + \"/\" + project_name + \"/\" + out_dir + \"/Delivery/tmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一. 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========  数据执行  ============\n",
    "\n",
    "# ====  一. 函数定义  ====\n",
    "def deal_ID_length(df):\n",
    "    # ID不足7位的补足0到6位\n",
    "    # 国药诚信医院编码长度是7位数字，cpa医院编码是6位数字。\n",
    "    df = df.withColumn(\"ID\", df[\"ID\"].cast(StringType()))\n",
    "    # 去掉末尾的.0\n",
    "    df = df.withColumn(\"ID\", func.regexp_replace(\"ID\", \"\\\\.0\", \"\"))\n",
    "    df = df.withColumn(\"ID\", func.when(func.length(df.ID) < 7, func.lpad(df.ID, 6, \"0\")).otherwise(df.ID))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHWA\n",
    "if project_name == \"NHWA\":\n",
    "    @udf(StringType())\n",
    "    def for_ACC(name):\n",
    "        # ACC1/ACC2\n",
    "        if name in [\"咪达唑仑\", \"右美托咪定\"]:\n",
    "            newname = \"ACC1\"\n",
    "        elif name in [\"丙泊酚\", \"依托咪酯\",\"芬太尼\",\"瑞芬太尼\",\"舒芬太尼\"]:\n",
    "            newname = \"ACC2\"\n",
    "        else:\n",
    "            newname = \"-\"\n",
    "        return newname\n",
    "\n",
    "    @udf(StringType())\n",
    "    def for_region(pro, acc):\n",
    "        # 区域\n",
    "        if pro in [\"黑龙江\",\"吉林\",\"辽宁\"] and (acc == \"ACC1\"):\n",
    "            newname = \"东北区\"\n",
    "        elif pro in [\"北京\",\"天津\",\"上海\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华北一区\"\n",
    "        elif pro in [\"河北\",\"山西\",\"内蒙古\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华北二区\"\n",
    "        elif pro in [\"江苏\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华东一区\"\n",
    "        elif pro in [\"浙江\",\"福建\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华东二区\"\n",
    "        elif pro in [\"湖南\",\"湖北\",\"江西\"] and (acc == \"ACC1\"):\n",
    "            newname = \"中南区\"\n",
    "        elif pro in [\"广东\",\"广西\",\"海南\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华南区\"\n",
    "        elif pro in [\"重庆\",\"四川\"] and (acc == \"ACC1\"):\n",
    "            newname = \"西南一区\"\n",
    "        elif pro in [\"贵州\",\"云南\"] and (acc == \"ACC1\"):\n",
    "            newname = \"西南二区\"\n",
    "        elif pro in ['河南',\"陕西\",\"宁夏\",\"新疆\"] and (acc == \"ACC1\"):\n",
    "            newname = \"西北一区\"\n",
    "        elif pro in [\"安徽\",\"山东\"] and (acc == \"ACC1\"):\n",
    "            newname = \"华东三区\"    \n",
    "        elif pro in [\"黑龙江\",\"吉林\",\"辽宁\"] and (acc == \"ACC2\"):\n",
    "            newname = \"东北区\"\n",
    "        elif pro in [\"北京\",\"天津\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华北一区\"\n",
    "        elif pro in [\"河北\",\"山西\",\"内蒙古\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华北二区\"\n",
    "        elif pro in [\"江苏\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华东一区\"\n",
    "        elif pro in [\"浙江\",\"福建\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华东二区\"\n",
    "        elif pro in [\"湖南\",\"湖北\",\"江西\"] and (acc == \"ACC2\"):\n",
    "            newname = \"中南区\"\n",
    "        elif pro in [\"广东\",\"广西\",\"海南\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华南区\"\n",
    "        elif pro in [\"重庆\",\"四川\"] and (acc == \"ACC2\"):\n",
    "            newname = \"西南一区\"\n",
    "        elif pro in [\"贵州\",\"云南\"] and (acc == \"ACC2\"):\n",
    "            newname = \"西南二区\"\n",
    "        elif pro in ['河南',\"陕西\",\"宁夏\",\"新疆\"] and (acc == \"ACC2\"):\n",
    "            newname = \"西北一区\"\n",
    "        elif pro in [\"安徽\",\"山东\"] and (acc == \"ACC2\"):\n",
    "            newname = \"华东三区\"\n",
    "        elif pro in [\"上海\"] and (acc == \"ACC2\"):\n",
    "            newname = \"上海区\" \n",
    "        else:\n",
    "            newname = \"-\"\n",
    "        return newname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二. 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====  二. 数据准备  ====  \n",
    "\n",
    "# 1. hospital_map：ID - 医院名称\n",
    "# 1.1 CPA_GYC_hospital_map\n",
    "CPA_GYC_hospital_map0 = spark.read.parquet(CPA_GYC_hospital_map_path)\n",
    "CPA_GYC_hospital_map0 = CPA_GYC_hospital_map0.select(\"医院编码\", \"医院名称\", \"等级\" ,\"标准化省份\", \"标准化城市\", \"新版ID\", \"Source\").distinct() \\\n",
    "                            .withColumnRenamed(\"医院编码\", \"ID\")\n",
    "CPA_GYC_hospital_map0 = CPA_GYC_hospital_map0.withColumn('ID', col('ID').cast(IntegerType()))\n",
    "# 优先选择cpa医院名\n",
    "id_window = Window.partitionBy('新版ID').orderBy(col('ID'))\n",
    "CPA_GYC_hospital_map1 = CPA_GYC_hospital_map0.withColumn('rank',func.row_number().over(id_window))\n",
    "CPA_GYC_hospital_map2 = CPA_GYC_hospital_map1.where(col('rank') == 1).select('新版ID', '医院名称') \\\n",
    "                            .withColumnRenamed(\"医院名称\", \"统一名称\")\n",
    "CPA_GYC_hospital_map3 = CPA_GYC_hospital_map1.join(CPA_GYC_hospital_map2, on='新版ID', how='left')\n",
    "CPA_GYC_hospital_map = CPA_GYC_hospital_map3.select('ID', '统一名称', '等级').distinct()\n",
    "CPA_GYC_hospital_map = deal_ID_length(CPA_GYC_hospital_map)\n",
    "\n",
    "# 1.2 HAIHONG_hospital_map 海虹编码\n",
    "HAIHONG_hospital_map = spark.read.parquet(HAIHONG_hospital_map_path)\n",
    "HAIHONG_hospital_map = HAIHONG_hospital_map.select('医院编码', '医院名称', '等级').distinct() \\\n",
    "                                        .withColumnRenamed(\"医院编码\", \"ID\") \\\n",
    "                                        .withColumnRenamed(\"医院名称\", \"统一名称\")\n",
    "\n",
    "# 1.3 合并\n",
    "hospital_map = CPA_GYC_hospital_map.union(HAIHONG_hospital_map)\n",
    "\n",
    "# 2. hospital_map：ID - 新版名称\n",
    "CPA_GYC_hospital_map0 = spark.read.parquet(CPA_GYC_hospital_map_path)\n",
    "hospital_map_newname = CPA_GYC_hospital_map0.select(\"医院编码\", \"新版名称\", '等级') \\\n",
    "                            .withColumnRenamed(\"医院编码\", \"ID\") \\\n",
    "                            .withColumnRenamed(\"新版名称\", \"统一名称\") \\\n",
    "                            .dropDuplicates(['ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. province_city_mapping ：ID - 匹配省市\n",
    "province_city_mapping = spark.read.parquet(province_city_mapping_path)\n",
    "province_city_mapping = deal_ID_length(province_city_mapping)\n",
    "province_city_mapping = province_city_mapping.select('ID', 'Province', 'City').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. cpa_pha_mapping ：ID - 匹配PHA\n",
    "cpa_pha_mapping = spark.read.parquet(cpa_pha_mapping_path)\n",
    "cpa_pha_mapping = cpa_pha_mapping.where(cpa_pha_mapping[\"推荐版本\"] == 1) \\\n",
    "        .select(\"ID\", \"PHA\").distinct()\n",
    "cpa_pha_mapping = deal_ID_length(cpa_pha_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. product_map 文件\n",
    "product_map = spark.read.parquet(product_map_path)\n",
    "# a. 列名清洗统一\n",
    "# 有的min2结尾有空格与无空格的是两条不同的匹配\n",
    "if project_name == \"Sanofi\" or project_name == \"AZ\":\n",
    "    product_map = product_map.withColumnRenamed(product_map.columns[21], \"pfc\")\n",
    "if project_name == \"Eisai\":\n",
    "    product_map = product_map.withColumnRenamed(product_map.columns[22], \"pfc\")\n",
    "\n",
    "for i in product_map.columns:\n",
    "    if i in [\"标准通用名\", \"通用名_标准\", \"药品名称_标准\", \"S_Molecule_Name\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"通用名\")\n",
    "    if i in [\"min1_标准\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"min2\")\n",
    "    if i in [\"packcode\", \"Pack_ID\", \"Pack_Id\", \"PackID\", \"packid\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"pfc\")\n",
    "    if i in [\"商品名_标准\", \"S_Product_Name\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准商品名\")\n",
    "    if i in [\"剂型_标准\", \"Form_std\", \"S_Dosage\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准剂型\")\n",
    "    if i in [\"规格_标准\", \"Specifications_std\", \"药品规格_标准\", \"S_Pack\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准规格\")\n",
    "    if i in [\"包装数量2\", \"包装数量_标准\", \"Pack_Number_std\", \"S_PackNumber\", \"最小包装数量\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准包装数量\")\n",
    "    if i in [\"标准企业\", \"生产企业_标准\", \"Manufacturer_std\", \"S_CORPORATION\", \"标准生产厂家\"]:\n",
    "        product_map = product_map.withColumnRenamed(i, \"标准生产企业\")\n",
    "if project_name == \"Janssen\" or project_name == \"NHWA\":\n",
    "    if \"标准剂型\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"剂型\", \"标准剂型\")\n",
    "    if \"标准规格\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"规格\", \"标准规格\")\n",
    "    if \"标准生产企业\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"生产企业\", \"标准生产企业\")\n",
    "    if \"标准包装数量\" not in product_map.columns:\n",
    "        product_map = product_map.withColumnRenamed(\"包装数量\", \"标准包装数量\")\n",
    "\n",
    "# b. min2处理\n",
    "product_map = product_map.withColumn(\"min2\", func.regexp_replace(\"min2\", \"&amp;\", \"&\")) \\\n",
    "                        .withColumn(\"min2\", func.regexp_replace(\"min2\", \"&lt;\", \"<\")) \\\n",
    "                        .withColumn(\"min2\", func.regexp_replace(\"min2\", \"&gt;\", \">\"))\n",
    "\n",
    "if 'Route' not in product_map.columns:\n",
    "    product_map = product_map.withColumn('Route', func.lit('-'))\n",
    "    \n",
    "# c. 列处理\n",
    "product_map = product_map.withColumn(\"pfc\", product_map[\"pfc\"].cast(IntegerType())) \\\n",
    "                    .withColumn(\"标准包装数量\", product_map[\"标准包装数量\"].cast(IntegerType())) \\\n",
    "                    .withColumnRenamed(\"pfc\", \"PACK_ID\") \\\n",
    "                    .distinct()\n",
    "\n",
    "# d. pfc为0统一替换为null\n",
    "product_map = product_map.withColumn(\"PACK_ID\", func.when(col('PACK_ID') == 0, None).otherwise(col('PACK_ID'))).distinct()\n",
    "\n",
    "# e 选取需要的列(不同项目有区别)\n",
    "if project_name == 'NHWA':\n",
    "    product_map = product_map \\\n",
    "                .select(\"min1\", \"PACK_ID\", \"通用名\", \"标准商品名\", \"标准剂型\", \"标准规格\", \"标准包装数量\", \"标准生产企业\", 'Route', \n",
    "                       \"min2\", \"商品名+SKU\", \"毫克数\") \n",
    "else:\n",
    "    product_map = product_map \\\n",
    "                .select(\"min1\", \"PACK_ID\", \"通用名\", \"标准商品名\", \"标准剂型\", \"标准规格\", \"标准包装数量\", \"标准生产企业\", 'Route', 'min2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.样本数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 提取交付数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====  Raw =====\n",
    "\n",
    "# 1. 读取交付数据\n",
    "monthlist = range(time_left, time_right+1, 1)\n",
    "path_list = [raw_standard_path + '/Date_copy=' + str(i) for i in monthlist]\n",
    "index = 0\n",
    "for eachpath in path_list:\n",
    "    df = spark.read.parquet(eachpath)\n",
    "    if index ==0:\n",
    "        data_standard = df\n",
    "    else:\n",
    "        data_standard = data_standard.union(df)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 信息匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 信息匹配\n",
    "data_standard = deal_ID_length(data_standard)\n",
    "data_standard_map_info = data_standard.select(\"Date\", \"ID\", \"Brand\", \"Form\", \"Specifications\", \"Pack_Number\", \"Manufacturer\", \n",
    "                                              \"Sales\", \"Units\", \"min1\", \"Molecule\")\n",
    "if project_name == 'XLT':\n",
    "    # XLT 用新版名称（因为后续匹配医院编号文件的需要）\n",
    "    hospital_map = hospital_map_newname\n",
    "\n",
    "data_standard_map_info = data_standard_map_info.join(product_map.dropDuplicates(['min1']), on=[\"min1\"], how='left') \\\n",
    "                                                .join(hospital_map, on='ID', how='left') \\\n",
    "                                                .join(province_city_mapping, on='ID', how='left') \\\n",
    "                                                .join(cpa_pha_mapping, on='ID', how='left').persist()\n",
    "\n",
    "# XLT 多了一些匹配信息\n",
    "if project_name == 'XLT':\n",
    "    # 5323003 没有PHA  \n",
    "    # 1. 省市标准化\n",
    "    Province_City_map = spark.read.csv(Province_City_map_path, header=True)\n",
    "    data_standard_map_info = data_standard_map_info.join(Province_City_map.select('Servier_Province','XLT_Province').distinct(), \n",
    "                                                        data_standard_map_info.Province == Province_City_map.XLT_Province, how='left') \\\n",
    "                                           .join(Province_City_map.select('Servier_City','XLT_City').distinct(), \n",
    "                                                        data_standard_map_info.City == Province_City_map.Servier_City, how='left')\n",
    "    data_standard_map_info = data_standard_map_info.withColumn('Province', func.when(~col('Servier_Province').isNull(), col('Servier_Province')) \\\n",
    "                                                                               .otherwise(col('Province'))) \\\n",
    "                                                   .withColumn('City', func.when(~col('XLT_City').isNull(), col('XLT_City')) \\\n",
    "                                                                               .otherwise(col('City'))) \\\n",
    "                                                    .drop('Servier_Province','XLT_Province', 'Servier_City','XLT_City')\n",
    "    # 2. 匹配区域\n",
    "    # Region_map = spark.read.csv(Region_map_path, header=True)    \n",
    "    # Region_map = Region_map.withColumnRenamed('省份', 'Province') \\\n",
    "    #                         .select('Province', '区域').distinct()\n",
    "\n",
    "    china_Region_map = spark.read.csv(china_Region_map_path, header=True)\n",
    "    china_Region_map = china_Region_map.withColumnRenamed('省份', 'Province') \\\n",
    "                                        .select('南北中国', '区域','Province').distinct()\n",
    "    \n",
    "    # 3. PTD匹配\n",
    "    PTD_map = spark.read.csv(PTD_map_path, header=True)\n",
    "    PTD_map = PTD_map.select('商品名+SKU', 'PTD系数').distinct() \\\n",
    "                    .withColumnRenamed('商品名+SKU', 'min2')\n",
    "                    \n",
    "    \n",
    "    data_standard_map_info = data_standard_map_info.withColumn('min2', func.regexp_replace(\"min2\", \"\\\\|\", \"\")) \\\n",
    "                                                    .join(Region_map, on='Province', how='left') \\\n",
    "                                                    .join(china_Region_map, on='Province', how='left') \\\n",
    "                                                    .join(PTD_map, on='min2', how='left').persist()\n",
    "        \n",
    "    # 4.医院编号匹配\n",
    "    Hospital_id_map = spark.read.csv(Hospital_id_map_path, header=True)\n",
    "    Hospital_id_map = Hospital_id_map.withColumnRenamed('Hosp_name', '统一名称').distinct()\n",
    "    data_standard_map_info = data_standard_map_info.join(Hospital_id_map, on='统一名称', how='left').persist()        \n",
    "        \n",
    "        \n",
    "# NHWA 多了一些匹配信息        \n",
    "if project_name == 'NHWA':\n",
    "    \n",
    "    # 魔方信息\n",
    "    mofang_map = spark.read.csv(mofang_map_path, header=True)\n",
    "    mofang_map = mofang_map.withColumn('mofang_prod', func.concat(col('药品名称'), col('商品名'), col('剂型'),\n",
    "                                                                   col('规格'), col('生产企业'))) \\\n",
    "                            .withColumn('mofang_prod', func.regexp_replace(\"mofang_prod\", \" \", \"\")) \\\n",
    "                            .select('mofang_prod', '药品索引').distinct()\n",
    "    \n",
    "    # 城市tier信息\n",
    "    city_tier = spark.read.csv(city_tier_path, header=True)\n",
    "    city_tier = city_tier.withColumnRenamed('City Name', 'City') \\\n",
    "                    .withColumnRenamed('City.Tier.2010', 'BMS_Segment')\n",
    "    \n",
    "    # 旧的医院名信息  \n",
    "    CPA_GYC_hospital_map_old = spark.read.csv(CPA_GYC_hospital_map_old_path, header=True)\n",
    "    CPA_GYC_hospital_map_old = CPA_GYC_hospital_map_old.groupby('CPA') \\\n",
    "                                    .agg(func.first('PHA Hosp name').alias('Hosp_name'), func.first('PHA ID').alias('HOSP_ID')) \\\n",
    "                                    .withColumnRenamed('CPA', 'ID')\n",
    "    CPA_GYC_hospital_map_old = deal_ID_length(CPA_GYC_hospital_map_old)\n",
    "    \n",
    "    # 匹配\n",
    "    data_standard_map_info = data_standard_map_info.withColumn('mofang_prod', func.concat(col('Molecule'), col('Brand'), col('Form'),\n",
    "                                                                   col('Specifications'), col('Manufacturer'))) \\\n",
    "                                                    .withColumn('mofang_prod', func.regexp_replace(\"mofang_prod\", \" \", \"\")) \\\n",
    "                                                    .join(mofang_map, on='mofang_prod', how='left') \\\n",
    "                                                    .join(CPA_GYC_hospital_map_old, on='ID', how='left') \\\n",
    "                                                    .join(city_tier, on='City', how='left').fillna(\"5\", 'BMS_Segment').persist()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.列名统一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列名统一\n",
    "if project_name == 'NHWA':\n",
    "    rename_list = {'Date':'年月', 'City':'城市', 'Province':'省份', 'ID':'医院编码',\n",
    "                    '通用名':'分子名', '标准商品名':'标准商品名', \n",
    "                    '标准剂型':'剂型', '标准规格':'规格', '标准包装数量':'包装数量', '标准生产企业':'生产企业_标准',\n",
    "                    'Hosp_name':'医院名称', '统一名称':'医院名称II', 'PHA':'医院编码_标准',\n",
    "                    'Sales':'销售金额', 'Units':'销售数量'}\n",
    "elif project_name == 'XLT':\n",
    "    rename_list = {'Date':'Date', 'City':'城市', 'Province':'省份', 'ID':'ID',\n",
    "                   '通用名':'通用名', '标准商品名':'商品名', \n",
    "                    '标准剂型':'剂型', '标准规格':'规格', '标准包装数量':'包装数量', '标准生产企业':'生产企业',\n",
    "                    '统一名称':'Hosp_name', 'PHA':'Panel_ID',\n",
    "                    'Sales':'销售金额', 'Units':'销售数量(片)', \n",
    "                    'min2':'商品名+SKU'}\n",
    "else:\n",
    "    rename_list = {'Date':'年月', 'City':'城市', 'Province':'省份', 'ID':'医院编码',\n",
    "                    '通用名':'通用名', '标准商品名':'商品名', \n",
    "                    '标准剂型':'剂型', '标准规格':'规格', '标准包装数量':'包装数量', '标准生产企业':'生产企业',\n",
    "                    '统一名称':'医院名称', 'PHA':'PHA编码', 'Route':'给药途径',\n",
    "                    'Sales':'金额', 'Units':'数量'}\n",
    "\n",
    "for old_name, newname in rename_list.items():\n",
    "    data_standard_map_info = data_standard_map_info.withColumnRenamed(old_name, newname)\n",
    "    \n",
    "# 列选择\n",
    "if project_name != 'NHWA':\n",
    "    if project_name == 'XLT':\n",
    "        data_standard_delivery_out = data_standard_map_info.select(\"Date\",\"Hosp_name\",\"ID\",\"Panel_ID\",\"商品名\",\"商品名+SKU\",\n",
    "                      \"城市\",\"省份\",\"区域\",\"医院编号\", \"销售金额\",\"销售数量(片)\",\"通用名\",\"规格\", \"包装数量\",\"南北中国\",'PTD系数','生产企业')\n",
    "    else:\n",
    "        data_standard_delivery_out = data_standard_map_info.select('年月', '省份', '城市', '医院编码', '金额', '数量', '通用名', '商品名', '剂型',\n",
    "                                                      '规格', '包装数量', '生产企业', '医院名称', '等级', 'PHA编码', '给药途径')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.最终交付处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if project_name == 'XLT':\n",
    "    \n",
    "    # 筛选分子\n",
    "    mole_list = ['阿利沙坦酯','奥美沙坦','奥美沙坦/氨氯地平','厄贝沙坦','氯沙坦','培哚普利','培哚普利/氨氯地平',\n",
    "               '缬沙坦','缬沙坦/氨氯地平','坎地沙坦','替米沙坦']\n",
    "    df = data_standard_delivery_out.where(col('通用名').isin(mole_list))\n",
    "    \n",
    "    # 输出没匹配到PTD的条目\n",
    "    noPTD = df.where(col('PTD系数').isNull()).select(\"通用名\", \"商品名\", \"商品名+SKU\", \"PTD系数\").distinct()\n",
    "    if noPTD.count() > 0:\n",
    "        noPTD = noPTD.repartition(1)\n",
    "        noPTD.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "            .mode(\"overwrite\").save(out_noPTD_path)\n",
    "    \n",
    "    df1 = df.withColumn('市场', func.lit('高血压市场')) \\\n",
    "                                    .withColumn('年', func.substring(col('Date'), 0, 4).cast(IntegerType())) \\\n",
    "                                    .withColumn('月', func.substring(col('Date'), 5, 2).cast(IntegerType())) \\\n",
    "                                    .withColumn('销售数量(盒)', col('销售数量(片)')/col('包装数量')) \\\n",
    "                                    .withColumn('销售数量(盒)', func.round(col('销售数量(盒)'), 0).cast(IntegerType()))\n",
    "    df2 = df1.where(col('商品名') != 'Others') \\\n",
    "            .withColumn('区域', func.when(col('区域').isin('华东1区'), func.lit('华东区')).otherwise(col('区域'))) \\\n",
    "            .withColumn('区域', func.when(col('区域').isin('华东2区'), func.lit('华中区')).otherwise(col('区域')))\n",
    "    \n",
    "    out = df2.withColumn('商品名', func.when(col('商品名') == col('通用名'), func.concat_ws('+', col('通用名'), col('生产企业'))) \\\n",
    "                                    .otherwise(col('商品名'))) \\\n",
    "            .drop('生产企业')\n",
    "    \n",
    "    out = out.select(\"Date\",\"Hosp_name\",\"ID\",\"Panel_ID\",\"商品名\",\"商品名+SKU\",\"城市\",\"市场\",\"年\",\"月\",\"省份\",\"区域\",\"医院编号\",\n",
    "                      \"销售金额\",\"销售数量(片)\",\"销售数量(盒)\",\"通用名\",\"规格\",\"包装数量\",\"南北中国\",'PTD系数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if project_name in ['贝达', '康哲', '奥鸿', '京新', '海坤', '汇宇', 'Tide']:\n",
    "    out = data_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"医院编码\", \"医院名称\", \"等级\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                       \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "\n",
    "if project_name in ['神州', 'Qilu']:\n",
    "    out = data_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"医院编码\", \"PHA编码\", \"医院名称\", \"等级\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                       \"包装数量\", \"生产企业\", \"金额\", \"数量\")\n",
    "\n",
    "if project_name in ['Gilead']:\n",
    "    out = data_standard_delivery_out.select(\"年月\", \"省份\", \"城市\", \"医院编码\", \"医院名称\", \"等级\", \"通用名\", \"商品名\", \"剂型\", \"规格\", \n",
    "                                                       \"包装数量\", \"生产企业\", \"金额\", \"数量\", \"给药途径\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHWA 处理较多\n",
    "if project_name == 'NHWA':\n",
    "    df = data_standard_delivery.groupby('年月', '省份', '城市', '医院编码', '分子名', '标准商品名', '剂型',\n",
    "                                                      '规格', '包装数量', '生产企业_标准', '医院名称', '医院名称II', '医院编码_标准', 'min2', \n",
    "                                                       '商品名+SKU', '药品索引', 'BMS_Segment') \\\n",
    "                                .agg(func.sum('销售金额').alias('销售金额'), func.sum('销售数量').alias('销售数量'), \n",
    "                                     func.sum('毫克数').alias('毫克数'))\n",
    "\n",
    "    df2 = df.withColumn('省', func.regexp_replace(\"省份\", \"省|回族自治区|壮族自治区|维吾尔族自治区|维吾尔自治区|自治区|市\", \"\"))\n",
    "    # 根据分子名定义ACC1/ACC2\n",
    "    df2 = df2.withColumn('ACC1/ACC2', for_ACC(col('分子名')))\n",
    "    # 根据省和ACC1/ACC2定义区域\n",
    "    df2 = df2.withColumn('区域', for_region(col('省'), col('ACC1/ACC2')))\n",
    "    # 710133 raw是陕西 - map是北京\n",
    "    # 华北一区 4684,  4725\n",
    "    # 西北一区 10103,  10062\n",
    "\n",
    "    df2 = df2.withColumn('市场I', func.lit(\"麻醉市场\")) \\\n",
    "            .withColumn('市场II', func.lit(None).cast(StringType())) \\\n",
    "            .withColumn('市场III', func.lit(None).cast(StringType())) \\\n",
    "            .withColumn('标准商品名', func.when(col('标准商品名') == \"乐维伽\", func.lit(\"右美宁\")).otherwise(col('标准商品名'))) \\\n",
    "            .fillna(0, '毫克数') \\\n",
    "            .withColumn('销售毫克数', col('销售数量')*col('毫克数')) \\\n",
    "            .withColumn('power', func.concat(col('分子名'), col('区域'))) \\\n",
    "            .withColumn('年', func.substring(col('年月'), 0, 4)) \\\n",
    "            .withColumn('月', func.substring(col('年月'), 4, 2))\n",
    "\n",
    "    out = df2.select('医院编码', '医院编码_标准', '医院名称', 'min2', '销售金额', '销售数量', '市场I', '规格', '剂型', '包装数量', '商品名+SKU', \n",
    "              '标准商品名', '生产企业_标准', '分子名', '毫克数', '年', '月', '省份', '城市', 'BMS_Segment', '市场II', '市场III', 'ACC1/ACC2', '区域', \n",
    "               '销售毫克数', 'power', '医院名称II', '药品索引')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.结果输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果输出\n",
    "out = out.repartition(1)\n",
    "out.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "       .mode(\"overwrite\").save(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out.agg(func.sum('销售金额'), func.sum('销售数量(片)'), func.sum('销售数量(盒)')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out.agg(*[func.count(func.when(func.isnull(c), c)).alias(c) for c in out.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
