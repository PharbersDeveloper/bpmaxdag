{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extraordinary-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "# YARN URL: http://161.189.223.227:8088/cluster\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# prepare\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"sshe write new_project in jupyter using python3\") \\\n",
    "    .config('spark.sql.codegen.wholeStage', False) \\\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', True) \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID\", \"AKIAWPBDTVEAEU44ZAGT\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"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\")\n",
    "if access_key:\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.cn-northwest-1.amazonaws.com.cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "maritime-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType, StringType, StructType, StructType\n",
    "from pyspark.sql.functions import col, date_format, count, isnull\n",
    "from pyspark.sql.functions import when, isnan, udf, pandas_udf, PandasUDFType\n",
    "from pyspark.sql import functions as Func\n",
    "from pyspark.sql import DataFrame    \n",
    "\n",
    "from typing import Iterator\n",
    "\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "instant-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "## ====== 输入文件和输出文件 ======\n",
    "\n",
    "# \n",
    "g_whether_save_result = True\n",
    "\n",
    "p_main_dir = \"s3a://ph-origin-files/user/zazhao/2020年结果-csv/\"\n",
    "p_patient = p_main_dir + \"病人\"\n",
    "p_detection = p_main_dir + \"检测\"\n",
    "p_data_summary = p_main_dir+\"条目数汇总表-2020.csv\"\n",
    "\n",
    "p_out_main_dir = p_main_dir+\"输出文件/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colored-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "\n",
    "## 读取条目数汇总 \n",
    "df_summary_sample = spark.read.format(\"csv\").load(p_main_dir+\"条目数汇总表-2020.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "optional-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "## 读取检测数据\n",
    "df_raw_detection = spark.read.csv(p_detection, header=True)\n",
    "\n",
    "df_raw_detection = df_raw_detection.select([ 'PATIENT_ID', 'VISIT_ID', 'ITEM_NAME', 'SUBJECT', 'REPORT_ITEM_NAME', \n",
    "                                            'RESULT', 'UNITS', 'ABNORMAL_INDICATOR', 'REQUESTED_DATE_TIME', \n",
    "                                            'RESULTS_RPT_DATE_TIME', 'DEPT_NAME'])\n",
    "\n",
    "df_raw_detection = df_raw_detection.withColumn(\"VISIT_ID\", Func.col(\"VISIT_ID\").cast(\"int\"))\\\n",
    "                                    .withColumnRenamed(\"VISIT_ID\", \"就诊序号\") \\\n",
    "                                    .withColumn(\"REQUESTED_DATE_TIME_STD\",  date_format(\"REQUESTED_DATE_TIME\", \"yyyMM\")) \\\n",
    "                                    .withColumn(\"RESULTS_RPT_DATE_TIME_STD\", date_format(\"RESULTS_RPT_DATE_TIME\", \"yyyMM\")) \n",
    "# df_raw_detection.where( df_raw_detection[\"VISIT_ID\"].isNull() ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "informational-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "## 读取病人数据\n",
    "\n",
    "df_raw_patient = spark.read.csv( p_patient, header=True)\n",
    "\n",
    "old_col = ['省份', '城市', '医院等级', '就诊类型', '医院ID', '患者ID', '就诊序号', \n",
    "        '处方日期', '入院时间', '出院时间', '年龄', \n",
    "        '性别', '医保类型', '诊断', '科室', \n",
    "        '药品名称', '规格', '剂型', '厂家', '金额', '数量', '数量单位']\n",
    "new_col = [\"PROVINCE\", \"CITY\", \"HOSP_LEVEL\", \"TREAMENT_TYPE\", \"HOSP_ID\", \"PATIENT_ID\", \"VISIT_ID\",\n",
    "          \"PRESCRIPTION_DATE\", \"ADMISSION_DATE\" , \"DISCHARGE_DATE\",  \"AGE\", \n",
    "         \"GENDER\", \"HIS_TYPE\", \"DIAGNOISE\", \"DEPT_NAME\",\n",
    "          \"DRUG_NAME\", \"SPECIFICATION\", \"FORM\", \"MANUFACTURES\", \"MONEY\", \"NUMBER\", \"NUMBER_UNIT\"]\n",
    "\n",
    "df_raw_patient = df_raw_patient.select(old_col)\n",
    "\n",
    "\n",
    "## 去除字符串前后的空格,因为会影响到和其他表间进行匹配\n",
    "df_raw_patient = df_raw_patient.select([Func.trim(col(i)).alias(i)  for i in df_raw_patient.columns])\n",
    "\n",
    "###################### 以下是需要转换列名为英文时才需要 \n",
    "# # 列名标准化\n",
    "# data_patient = data_patient.select( list( map( lambda x:col(x[0]).alias(x[1]),  zip(old_col, new_col) ) ))\n",
    "# # 转换日期格式\n",
    "# data_patient = data_patient.withColumn(\"PRESCRIPTION_DATE_STD\", date_format(\"PRESCRIPTION_DATE\", \"yyyMM\") )\\\n",
    "#                                     .withColumn(\"ADMISSION_DATE_STD\", date_format(\"ADMISSION_DATE\", \"yyyMM\") )\\\n",
    "#                                     .withColumn(\"DISCHARGE_DATE_STD\", date_format(\"DISCHARGE_DATE\", \"yyyMM\") )\n",
    "# ## 年龄转换成数字\n",
    "# df_patient = df_patient.withColumn(\"AGE\", col(\"AGE\").cast(\"int\"))\n",
    "######################\n",
    "\n",
    "## 日期格式转换\n",
    "df_raw_patient = df_raw_patient.withColumn(\"处方日期\", date_format(\"处方日期\", \"yyyMM\") )\\\n",
    "                                    .withColumn(\"入院时间\", date_format(\"入院时间\", \"yyyMM\") )\\\n",
    "                                    .withColumn(\"出院时间\", date_format(\"出院时间\", \"yyyMM\") )\n",
    "\n",
    "## 年龄转换成数字\n",
    "df_raw_patient = df_raw_patient.withColumn(\"年龄\", col(\"年龄\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "stainless-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "\n",
    "# df_raw_patient.where(col(\"入院时间\") ==\"201901\" ).groupBy(\"医院ID\").agg( Func.count(\"*\")).orderBy(\"医院ID\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "essential-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "## 数据条目比较\n",
    "\n",
    "# sample_patient = df_raw_patient.groupby(\"医院ID\").agg( Func.count(\"*\")).orderBy(\"医院ID\")\n",
    "# sample_patient.show()\n",
    "\n",
    "# df_summary_sample.show()\n",
    "\n",
    "# df_raw_detection.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "subject-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "## 初查1-数据完整性\n",
    "def checkOne(data_patient, save_result=False):\n",
    "    \n",
    "    #### 计算 check-1\n",
    "    # 统计存在空的字段\n",
    "    null_sample_num =  data_patient.select([ Func.count( when(  Func.isnull(c)| col(c).isNull(), c ) ).alias(c) \n",
    "                                            for c in data_patient.columns])\n",
    "#     null_sample_num.show(1, vertical=True)\n",
    "\n",
    "    # all_count = data_patient.select([col(c).count().alias(c) for c in data_patient.columns])\n",
    "    \n",
    "    # 统计非空的字段 \n",
    "    all_count = data_patient.select([Func.count(c).alias(c) for c in data_patient.columns])\n",
    "#     all_count.show(1, vertical=True)\n",
    "    \n",
    "    # 总的字段数\n",
    "    cc = data_patient.count()\n",
    "    \n",
    "    # 空缺率\n",
    "    dd = null_sample_num.select( list(map( lambda x: (null_sample_num[x]/cc*100).alias(x),  null_sample_num.columns)))\n",
    "#     dd.show(1,vertical=True)\n",
    "\n",
    "    last = all_count.union(null_sample_num).union(dd)\n",
    "    \n",
    "    if save_result==True:\n",
    "        output_file=  p_out_main_dir + \"初查表-1-数据完整性\"\n",
    "        last.repartition(1).write.mode(\"overwrite\").csv(output_file, sep=',', header=\"true\", encoding=\"utf-8\")\n",
    "\n",
    "checkOne(data_patient= df_raw_patient, save_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stuffed-palestinian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyspark/sql/pandas/functions.py:383: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " 省份         | 北京                                \n",
      " 城市         | 北京                                \n",
      " 医院等级     | 三甲                                \n",
      " 就诊类型     | 住院                                \n",
      " 医院ID       | SH0000005                           \n",
      " 患者ID       | 0003883910709aa39...                \n",
      " 就诊序号     | 1                                   \n",
      " 处方日期     | 202007                              \n",
      " 入院时间     | 202007                              \n",
      " 出院时间     | 202008                              \n",
      " 年龄         | 1                                   \n",
      " 性别         | 男                                  \n",
      " 医保类型     | 外埠医保                            \n",
      " 诊断         | 输尿管积水,输尿管积水,后尿道瓣膜... \n",
      " 科室         | 儿童泌尿外科病房                    \n",
      " 药品名称     | 注射用哌拉西林钠他唑巴坦钠(0.6...   \n",
      " 规格         | 0.625g华北制药                      \n",
      " 剂型         | 针剂                                \n",
      " 厂家         | 华北制药                            \n",
      " 金额         | 69.88                               \n",
      " 数量         | 2.0                                 \n",
      " 数量单位     | 瓶                                  \n",
      " 标准分子名称 | 哌拉西林他唑巴坦纳                  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "## 初查-2分子层面对比\n",
    "### 初步清洗分子名称\n",
    "\n",
    "\n",
    "@pandas_udf(\"string\", PandasUDFType.SCALAR)\n",
    "def change(iterator: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    new_iter = iterator.apply( lambda x: changeSpecification(x) )\n",
    "    return new_iter\n",
    "\n",
    "def changeSpecification(x ):\n",
    "    # 处理读入的字符为空的情况\n",
    "    if x==None:\n",
    "        return \"null\"\n",
    "    elif re.findall( r'.*(莫西沙星).*', x):\n",
    "        new_name = \"莫西沙星\"\n",
    "    elif re.findall( r'.*(左氧氟沙星).*', x):\n",
    "        new_name = \"左氧氟沙星\"\n",
    "    elif re.findall( r'.*(头孢曲松).*', x):\n",
    "        new_name = \"头孢曲松\"\n",
    "    elif re.findall( r'.*(阿奇霉素).*', x):\n",
    "        new_name = \"阿奇霉素\"\n",
    "    elif re.findall( r'.*(多西环素).*', x):\n",
    "        new_name = \"多西环素\"\n",
    "    elif re.findall( r'.*(米诺环素).*', x):\n",
    "        new_name = \"米诺环素\"\n",
    "    elif (re.findall( r'.*(他唑巴坦|他唑邦坦|三唑巴坦|他唑巴).*', x)!=list()) \\\n",
    "            & ( re.findall( r'.*(哌拉西林).*', x)!=list() ):\n",
    "        new_name = \"哌拉西林他唑巴坦纳\"\n",
    "    elif ( re.findall( r'.*(哌拉西林).*', x)!=list() )\\\n",
    "            & ( re.findall( r'.*(舒巴坦).*', x)!=list() ):\n",
    "        new_name = \"哌拉西林舒巴坦纳\"\n",
    "    elif re.findall( r'.*(哌拉西林).*', x):\n",
    "        new_name = \"哌拉西林纳\"\n",
    "    elif ( re.findall( r'.*(头孢哌酮).*', x)!=list() )\\\n",
    "            & ( re.findall( r'.*(舒巴坦).*', x)!=list() ):\n",
    "        new_name = \"头孢哌酮钠舒巴坦钠\"\n",
    "    elif ( re.findall( r'.*(头孢哌酮).*', x)!=list() )\\\n",
    "            & ( re.findall( r'.*(他唑巴坦).*', x)!=list() ):\n",
    "        new_name = \"头孢哌酮钠他唑巴坦钠\"\n",
    "    elif re.findall( r'.*(头孢哌酮).*', x):\n",
    "        new_name = \"头孢哌酮钠\"\n",
    "    elif ( re.findall( r'.*(美洛西林).*', x)!=list() )\\\n",
    "            & ( re.findall( r'.*(舒巴坦).*', x)!=list() ):\n",
    "        new_name = \"美洛西林钠舒巴坦钠\"\n",
    "    elif re.findall( r'.*(美洛西林).*', x):\n",
    "        new_name = \"美洛西林钠\"\n",
    "    elif re.findall( r'.*(依替米星).*', x):\n",
    "        new_name = \"依替米星\"\n",
    "    elif re.findall( r'.*(头孢米诺).*', x):\n",
    "        new_name = \"头孢米诺\"\n",
    "    elif re.findall( r'.*(替加环素).*', x):\n",
    "        new_name = \"替加环素\"\n",
    "    elif re.findall( r'.*(头孢西丁).*', x):\n",
    "        new_name = \"头孢西丁\"\n",
    "    elif re.findall( r'.*(头孢他啶).*', x):\n",
    "        new_name = \"头孢他啶\"\n",
    "    elif re.findall( r'.*(厄他培南).*', x):\n",
    "        new_name = \"厄他培南\"\n",
    "    elif re.findall( r'.*(利奈唑胺).*', x):\n",
    "        new_name = \"利奈唑胺\"    \n",
    "    elif re.findall( r'.*(万古霉素).*', x):\n",
    "        new_name = \"万古霉素\"\n",
    "    elif ( re.findall( r'.*(头孢噻肟).*', x)!=list()) & \\\n",
    "            ( re.findall( r'.*(舒巴坦).*', x)!=list()):\n",
    "        new_name = \"头孢噻肟舒巴坦钠\"\n",
    "    elif re.findall( r'.*(头孢噻肟).*', x):\n",
    "        new_name = \"头孢噻肟钠\"\n",
    "    elif re.findall( r'.*(拉氧头孢).*', x):\n",
    "        new_name = \"拉氧头孢\"\n",
    "    elif re.findall( r'.*(环丙沙星).*', x):\n",
    "        new_name = \"环丙沙星\"\n",
    "    else:\n",
    "        new_name =\"null\"\n",
    "    return new_name\n",
    "\n",
    "\n",
    "df_raw_patient = df_raw_patient.withColumn(\"标准分子名称\", change( Func.col(\"药品名称\") ) ) \n",
    "\n",
    "# data_patient.persist()\n",
    "# df_raw_patient.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "induced-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|入院时间|\n",
      "+--------+\n",
      "|  202006|\n",
      "|  202009|\n",
      "|  202007|\n",
      "|  202005|\n",
      "|  202004|\n",
      "|  202003|\n",
      "|  202001|\n",
      "|  202008|\n",
      "|  202002|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|入院时间|\n",
      "+--------+\n",
      "|  200206|\n",
      "|  201809|\n",
      "|  202006|\n",
      "|  201903|\n",
      "|  202009|\n",
      "|  201702|\n",
      "|  202007|\n",
      "|  201909|\n",
      "|  201808|\n",
      "|  202005|\n",
      "|  201806|\n",
      "|  201802|\n",
      "|  201911|\n",
      "|  202004|\n",
      "|  201703|\n",
      "|  201807|\n",
      "|  201907|\n",
      "|  201710|\n",
      "|  201805|\n",
      "|  201810|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "## 分子层面比对\n",
    "\n",
    "# 就诊类型有哪些\n",
    "# data_patient.select(\"TREAMENT_TYPE\").distinct().show()\n",
    "\n",
    "def unpivot(df, keys):\n",
    "    # 功能：数据宽变长\n",
    "    # 参数说明 df:dataframe,  keys 待转换表中需要保留的主键key，以list[]类型传入\n",
    "    # 转换是为了避免字段类不匹配，统一将数据转换为string类型，如果保证数据类型完全一致，可以省略该句\n",
    "    df = df.select(*[col(_).astype(\"string\") for _ in df.columns])\n",
    "    cols = [_ for _ in df.columns if _ not in keys]\n",
    "    stack_str = ','.join(map(lambda x: \"'%s', `%s`\" % (x, x), cols))\n",
    "    # feature, value 转换后的列名，可自定义\n",
    "    df = df.selectExpr(*keys, \"stack(%s, %s) as (feature, value)\" % (len(cols), stack_str))\n",
    "    return df\n",
    "\n",
    "# \n",
    "def checkTwoMethod( data_patient, treament_type, df_drug_name_all=None):\n",
    "    df_temp_patient = data_patient.where( data_patient[\"就诊类型\"]==treament_type)\n",
    "    \n",
    "    df_temp_patient = df_temp_patient.select([ \"医院ID\", \"就诊类型\", \"入院时间\", \"标准分子名称\", \"金额\", \"数量\"])\n",
    "#     df_temp_patient.select(\"入院时间\").distinct().show()\n",
    "#     return \n",
    "    \n",
    "    # 准备药品表\n",
    "#     df_drug_name_all = df_temp_patient.select(\"标准分子名称\").distinct().toPandas()[\"标准分子名称\"].values.tolist()\n",
    "    df_hosp_with_all_drug_pivot = df_temp_patient.where(col(\"标准分子名称\").isNotNull() ).groupBy([\"医院ID\", \"就诊类型\", \"入院时间\" ] )\\\n",
    "                                .pivot(\"标准分子名称\" ).count()\n",
    "    df_hosp_with_all_drug_pivot.show(1, vertical=True)\n",
    "    \n",
    "    df_hosp_with_all_drug_pivot = df_hosp_with_all_drug_pivot.withColumnRenamed(\"医院ID\", \"HOSP_ID\") \\\n",
    "                                                            .withColumnRenamed(\"就诊类型\", \"TREAMENT_TYPE\") \\\n",
    "                                                            .withColumnRenamed(\"入院时间\", \"DATE\") \n",
    "    df_hosp_with_all_drug = unpivot(df_hosp_with_all_drug_pivot, [ \"HOSP_ID\", \"TREAMENT_TYPE\", \"DATE\"] )\n",
    "    df_hosp_with_all_drug = df_hosp_with_all_drug.withColumnRenamed( \"HOSP_ID\", \"医院ID\") \\\n",
    "                                                            .withColumnRenamed( \"TREAMENT_TYPE\", \"就诊类型\") \\\n",
    "                                                            .withColumnRenamed(\"DATE\", \"入院时间\") \n",
    "    df_hosp_with_all_drug.show(1,  vertical=True)\n",
    "#     return \n",
    "    \n",
    "    df_hosp_with_all_drug = df_hosp_with_all_drug.withColumnRenamed(\"feature\", \"标准分子名称\")\\\n",
    "                                .withColumnRenamed(\"value\", \"条目数\")\n",
    "    #df_hosp_with_all_drug.show(50)\n",
    "    \n",
    "    # 统计药品的金额和数量\n",
    "    df_part_one = df_temp_patient.groupby([\"医院ID\", \"就诊类型\", \"入院时间\", \"标准分子名称\", ]).agg( \n",
    "                                                Func.count(\"*\").alias(\"总条目数\"), Func.sum( col(\"金额\") ).alias(\"药品层面总金额\"), \n",
    "                                                Func.sum( col(\"数量\") ).alias(\"药品层面总数量\")     )\n",
    "    # 统计医院层的金额和数量\n",
    "    df_part_two = df_temp_patient.groupby([\"医院ID\", \"就诊类型\", \"入院时间\" ]).agg( \n",
    "                                      Func.sum( col(\"金额\") ).alias(\"医院层面总金额\"), Func.sum( col(\"数量\") ).alias(\"医院层面总数量\")  )\n",
    "    \n",
    "    # 医院层和药品层的表join\n",
    "    df_part_three = df_part_one.join(df_part_two, on=[\"医院ID\", \"就诊类型\", \"入院时间\"] , how=\"inner\")\n",
    "\n",
    "    df_part_four = df_part_three.withColumn(\"金额占比\", col(\"药品层面总金额\")/col(\"医院层面总金额\") ) \\\n",
    "                                .withColumn(\"数量占比\", col(\"药品层面总数量\")/col(\"医院层面总数量\") )\n",
    "    \n",
    "    # \n",
    "    df_part_four = df_hosp_with_all_drug.join( df_part_four, on=[\"医院ID\", \"就诊类型\", \"入院时间\", \"标准分子名称\"], how=\"left\")\n",
    "    \n",
    "    df_part_four = df_part_four.orderBy([\"医院ID\", \"入院时间\", \"药品层面总金额\"], ascending=[1,1,0])\n",
    "    df_part_four.show(1, vertical=True)\n",
    "    return df_part_four\n",
    "\n",
    "def checkTwo(data_patient_, save_result=False ):\n",
    "    data_1 = checkTwoMethod(data_patient_, r\"门诊\")\n",
    "    data_2 = checkTwoMethod(data_patient_, r\"住院\")\n",
    "\n",
    "    if save_result == True:\n",
    "        temp =  data_1.select([\"医院ID\", \"就诊类型\", \"入院时间\",\"标准分子名称\", \"总条目数\", \"药品层面总金额\", \n",
    "                           \"金额占比\", \"药品层面总数量\", \"数量占比\"])\n",
    "        output_file=  p_out_main_dir+ \"初查表-2-门诊\"\n",
    "        temp.repartition(1).write.mode(\"overwrite\").csv(output_file, sep=',', header=\"true\", encoding=\"utf-8\")\n",
    "\n",
    "        temp =  data_2.select([\"医院ID\", \"就诊类型\", \"入院时间\",\"标准分子名称\", \"总条目数\", \"药品层面总金额\", \n",
    "                           \"金额占比\", \"药品层面总数量\", \"数量占比\"])\n",
    "        output_file=  p_out_main_dir+\"初查表-2-住院\"\n",
    "        temp.repartition(1).write.mode(\"overwrite\").csv(output_file, sep=',', header=\"true\", encoding=\"utf-8\")\n",
    "\n",
    "# checkTwo(df_raw_patient, save_result = True)\n",
    "checkTwo(df_raw_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "located-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "## 初查-3-4  医院数据连续性和稳定性 和 门诊住院比例 \n",
    "def checkThreeFour(df_patient, save_result=False):\n",
    "    \n",
    "    df_patient = df_patient.select(['省份', '城市', '医院等级', '就诊类型', '医院ID', '患者ID', '就诊序号', '处方日期', \n",
    "                               '入院时间', '出院时间', '年龄', '性别', '医保类型', '诊断', '科室', '药品名称', '规格', \n",
    "                               '剂型', '厂家', '金额', '数量', '数量单位' ])\n",
    "    \n",
    "    df_patient = df_patient.withColumn(\"年月\",  col(\"入院时间\"))\n",
    "    \n",
    "    # 医院数据连续性和稳定性\n",
    "    df_patient = df_patient.withColumn(\"门诊\",when(col(\"就诊类型\") == \"门诊\",1))\\\n",
    "                            .withColumn(\"住院\",when(col(\"就诊类型\") == \"住院\",0))   \n",
    "    df_patient = df_patient.select(\"医院ID\",\"入院时间\",\"数量单位\",\"年月\", \"金额\",\"患者ID\",\n",
    "                              \"就诊序号\",\"就诊类型\",\"门诊\",\"住院\").withColumn(\"金额\", col(\"金额\").cast(\"int\"))\n",
    "\n",
    "    year_month_list = [\"201901\",\"201902\",\"201903\",\"201904\",\"201905\",\"201906\",\n",
    "                                               \"201907\",\"201908\",\"201909\",\"201910\",\"201911\",\"201912\"]\n",
    "    \n",
    "    sample_table = df_patient.groupBy(\"医院ID\").pivot(\"年月\", year_month_list).count()\\\n",
    "                .fillna(0).orderBy([\"医院ID\" ], ascending=[1])\n",
    "    \n",
    "    peopel_num_table = df_patient.groupBy(\"医院ID\").pivot(\"年月\", year_month_list).agg(count(\"患者ID\")+count(\"就诊序号\"))\\\n",
    "                .fillna(0).orderBy([\"医院ID\"], ascending=[1])\n",
    "    money_table = df_patient.groupBy(\"医院ID\").pivot(\"年月\", year_month_list).sum(\"金额\")\\\n",
    "                .fillna(0).orderBy([\"医院ID\"], ascending=[1])\n",
    "    \n",
    "    # 门诊住院比例 \n",
    "    proportion = df_patient.groupBy(\"医院ID\", \"年月\").agg(count(col(\"门诊\")).alias(\"门诊总人数\"), count(col(\"住院\")).alias(\"住院总人数\") )\n",
    "    proportion = proportion.withColumn(\"radio\", col(\"门诊总人数\")/col(\"住院总人数\")).orderBy([\"医院ID\", \"年月\"], ascending=[1,1])\n",
    "    # proportion.show()\n",
    "\n",
    "    \n",
    "    if save_result==True:\n",
    "        output_file=  p_out_main_dir+\"初查表-3-条目数\"\n",
    "        sample_table.repartition(1).write.mode(\"overwrite\").csv(output_file, sep=',', header=\"true\", encoding=\"utf-8\")\n",
    "\n",
    "        output_file=  p_out_main_dir+\"初查表-3-总人次\"\n",
    "        peopel_num_table.repartition(1).write.mode(\"overwrite\").csv(output_file, sep=',', header=\"true\", encoding=\"utf-8\")\n",
    "\n",
    "        output_file=  p_out_main_dir+\"初查表-3-金额\"\n",
    "        money_table.repartition(1).write.mode(\"overwrite\").csv(output_file, sep=',', header=\"true\", encoding=\"utf-8\")\n",
    "\n",
    "        output_file=  p_out_main_dir+\"初查表-4-住院比例\"\n",
    "        proportion.repartition(1).write.mode(\"overwrite\").csv(output_file, sep=',', header=\"true\", encoding=\"utf-8\")\n",
    "\n",
    "checkThreeFour(df_raw_patient, save_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# IMS CHPA数据查询\n",
    "\n",
    "\n",
    "# MAX数据查询\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
