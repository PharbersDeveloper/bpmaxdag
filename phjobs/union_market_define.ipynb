{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phcli Jupyter Python Template\n",
    "# \n",
    "# 使用手册：\n",
    "# 1. 请将全局变量定义在第一个输入区内\n",
    "# 2. Phcli 会自动在第二个输入区初始化 Spark Session\n",
    "# 3. 所有 print 会在 phcli maxauto dag 后自动转为 logger.debug() 方法\n",
    "# 4. 请在第三个输入区开始编码，phcli maxauto dag 后会全部归类为一个方法\n",
    "\n",
    "\n",
    "# Config defined in here\n",
    "\n",
    "############## == config == ###################\n",
    "job_name = \"union_market_define\"\n",
    "job_runtime = \"python3\"\n",
    "job_command = \"submit\"\n",
    "job_timeout = 720.0\n",
    "############## == config == ###################\n",
    "\n",
    "\n",
    "# Variables defined in here\n",
    "\n",
    "############## == input args == ###################\n",
    "a = 123\n",
    "b = 456\n",
    "############## == input args == ###################\n",
    "\n",
    "############## == output args == ###################\n",
    "c = 'abc'\n",
    "d = 'def'\n",
    "############## == output args == ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "# YARN URL: http://161.189.223.227:8088/cluster\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# prepare\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"ywyuan write .union_market_define in jupyter using python3\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .config('spark.sql.codegen.wholeStage', False) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID\", \"AKIAWPBDTVEAEU44ZAGT\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"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\")\n",
    "if access_key:\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.cn-northwest-1.amazonaws.com.cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, BooleanType\n",
    "from pyspark.sql import functions as func\n",
    "import os\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packid市场名\n",
    "max_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "market_packid_AZ_path = max_path + \"/Common_files/extract_data_files/Market_definition_pack_level/AZ_definition_pack_level_20201120_lu.csv\"\n",
    "market_packid_Pfizer_path = max_path + \"/Common_files/extract_data_files/Market_definition_pack_level/Pfizer_definition_pack_level_20200525.csv\"\n",
    "market_packid_Sanofi_path = max_path  + \"/Common_files/extract_data_files/Market_definition_pack_level/Sanofi_definition_pack_level_20210105_lu.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_packid1 = spark.read.csv(market_packid_AZ_path, header=True)\n",
    "market_packid1 = market_packid1.select('Pack_ID', 'Market').distinct() \\\n",
    "                            .withColumn('market_define', func.lit('AZ'))\n",
    "\n",
    "market_packid2 = spark.read.csv(market_packid_Pfizer_path, header=True)\n",
    "market_packid2 = market_packid2.select('Pack_ID', 'Product Market').distinct() \\\n",
    "                            .withColumnRenamed('Product Market', 'Market') \\\n",
    "                            .withColumn('market_define', func.lit('Pfizer'))\n",
    "\n",
    "market_packid3 = spark.read.csv(market_packid_Sanofi_path, header=True)\n",
    "market_packid3 = market_packid3.select('Pack_ID', 'Market').distinct() \\\n",
    "                                .withColumn('market_define', func.lit('Sanofi'))\n",
    "\n",
    "market_packid = market_packid1.union(market_packid2).union(market_packid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选市场packid\n",
    "market_packid = market_packid.withColumn('Market', func.regexp_replace('Market',' |,', '_')) \\\n",
    "                                .withColumn('Pack_ID', market_packid['Pack_ID'].cast(IntegerType())) \\\n",
    "                                .withColumnRenamed('Pack_ID', 'PACK_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_packid = market_packid.repartition(1)\n",
    "market_packid.write.format(\"csv\").option(\"header\", \"true\") \\\n",
    "    .mode(\"overwrite\").save('s3a://ph-stream/common/public/max_result/0.0.5/market_define.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
