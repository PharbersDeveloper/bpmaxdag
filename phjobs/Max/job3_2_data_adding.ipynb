{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phcli Jupyter Python Template\n",
    "# \n",
    "# 使用手册：\n",
    "# 1. 请将全局变量定义在第一个输入区内\n",
    "# 2. Phcli 会自动在第二个输入区初始化 Spark Session\n",
    "# 3. 所有 print 会在 phcli maxauto dag 后自动转为 logger.debug() 方法\n",
    "# 4. 请在第三个输入区开始编码，phcli maxauto dag 后会全部归类为一个方法\n",
    "\n",
    "\n",
    "# Config defined in here\n",
    "\n",
    "############## == config == ###################\n",
    "job_name = \"job3_2_data_adding\"\n",
    "job_runtime = \"python3\"\n",
    "job_command = \"submit\"\n",
    "job_timeout = 720.0\n",
    "############## == config == ###################\n",
    "\n",
    "\n",
    "# Variables defined in here\n",
    "\n",
    "############## == input args == ###################\n",
    "max_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "project_name = \"Empty\"\n",
    "model_month_right = \"0\"\n",
    "max_month = \"0\"\n",
    "year_missing = \"0\"\n",
    "current_year = \"2020\"\n",
    "first_month = \"Empty\"\n",
    "current_month = \"Empty\"\n",
    "if_others = \"False\"\n",
    "monthly_update = \"Empty\"\n",
    "not_arrived_path = \"Empty\"\n",
    "published_path = \"Empty\"\n",
    "out_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "out_dir = \"Empty\"\n",
    "need_test = 0\n",
    "if_add_data = \"True\"\n",
    "############## == input args == ###################\n",
    "\n",
    "############## == output args == ###################\n",
    "c = 'abc'\n",
    "d = 'def'\n",
    "############## == output args == ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "# YARN URL: http://161.189.223.227:8088/cluster\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# prepare\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"ywyuan write Max.job3_2_data_adding in jupyter using python3\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .config('spark.sql.codegen.wholeStage', False) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID\", \"AKIAWPBDTVEAEU44ZAGT\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"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\")\n",
    "if access_key:\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.cn-northwest-1.amazonaws.com.cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, udf, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "'''\n",
    "project_name = \"Gilead\"\n",
    "model_month_right = \"201912\"\n",
    "first_month = \"1\"\n",
    "current_month = \"1\"\n",
    "monthly_update = \"True\"\n",
    "out_dir = \"202101\"\n",
    "current_year = '2021'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job3_data_adding\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print('job3_data_adding')\n",
    "\n",
    "if if_add_data != \"False\" and if_add_data != \"True\":\n",
    "    logger.error('wrong input: if_add_data, False or True') \n",
    "    raise ValueError('wrong input: if_add_data, False or True')\n",
    "\n",
    "if if_others == \"True\":\n",
    "    out_dir = out_dir + \"/others_box/\"\n",
    "\n",
    "out_path_dir = out_path + \"/\" + project_name + '/' + out_dir\n",
    "\n",
    "# 输入\n",
    "product_mapping_out_path = out_path_dir + \"/product_mapping_out\"\n",
    "products_of_interest_path = max_path + \"/\" + project_name + \"/poi.csv\"\n",
    "cpa_pha_mapping_path = max_path + \"/\" + project_name + \"/cpa_pha_mapping\"\n",
    "\n",
    "if year_missing:\n",
    "    year_missing = year_missing.replace(\" \",\"\").split(\",\")\n",
    "else:\n",
    "    year_missing = []\n",
    "year_missing = [int(i) for i in year_missing]\n",
    "model_month_right = int(model_month_right)\n",
    "max_month = int(max_month)\n",
    "\n",
    "# 月更新相关参数\n",
    "if monthly_update != \"False\" and monthly_update != \"True\":\n",
    "    print('wrong input: monthly_update, False or True') \n",
    "    raise ValueError('wrong input: monthly_update, False or True')\n",
    "\n",
    "if monthly_update == \"True\":\n",
    "    current_year = int(current_year)\n",
    "    first_month = int(first_month)\n",
    "    current_month = int(current_month)\n",
    "    if not_arrived_path == \"Empty\":    \n",
    "        not_arrived_path = max_path + \"/Common_files/Not_arrived\" + str(current_year*100 + current_month) + \".csv\"\n",
    "    if published_path == \"Empty\":\n",
    "        published_right_path = max_path + \"/Common_files/Published\" + str(current_year) + \".csv\"\n",
    "        published_left_path = max_path + \"/Common_files/Published\" + str(current_year - 1) + \".csv\"\n",
    "    else:\n",
    "        published_path  = published_path.replace(\" \",\"\").split(\",\")\n",
    "        published_left_path = published_path[0]\n",
    "        published_right_path = published_path[1]\n",
    "else:\n",
    "    current_year = model_month_right//100\n",
    "\n",
    "# published_left_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/Common_files/Published2019.csv\"\n",
    "# published_right_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/Common_files/Published2020.csv\"\n",
    "\n",
    "# 输出\n",
    "price_path = out_path_dir + \"/price\"\n",
    "price_city_path = out_path_dir + \"/price_city\"\n",
    "growth_rate_path = out_path_dir + \"/growth_rate\"\n",
    "adding_data_path =  out_path_dir + \"/adding_data\"\n",
    "raw_data_adding_path =  out_path_dir + \"/raw_data_adding\"\n",
    "new_hospital_path = out_path_dir + \"/new_hospital\"\n",
    "raw_data_adding_final_path =  out_path_dir + \"/raw_data_adding_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据检查-start\n",
      "数据检查-Pass\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =========== 数据检查 =============\n",
    "\n",
    "print('数据检查-start')\n",
    "\n",
    "# 存储文件的缺失列\n",
    "misscols_dict = {}\n",
    "\n",
    "# product_mapping_out file\n",
    "raw_data = spark.read.parquet(product_mapping_out_path)\n",
    "colnames_raw_data = raw_data.columns\n",
    "misscols_dict.setdefault(\"product_mapping_out\", [])\n",
    "\n",
    "colnamelist = ['min1', 'PHA', 'City', 'year_month', 'ID',  'Brand', 'Form',\n",
    "'Specifications', 'Pack_Number', 'Manufacturer', 'Molecule', 'Source',\n",
    "'Sales', 'Units', 'Path', 'Sheet', 'BI_hospital_code', 'Province', \n",
    "'Month', 'Year', 'City_Tier_2010', 'min2', 'S_Molecule', 'std_route', \"标准商品名\"]\n",
    "#'Raw_Hosp_Name','ORG_Measure','Units_Box', 'Corp', 'Route',\n",
    "\n",
    "for each in colnamelist:\n",
    "    if each not in colnames_raw_data:\n",
    "        misscols_dict[\"product_mapping_out\"].append(each)\n",
    "\n",
    "# 判断输入文件是否有缺失列\n",
    "misscols_dict_final = {}\n",
    "for eachfile in misscols_dict.keys():\n",
    "    if len(misscols_dict[eachfile]) != 0:\n",
    "        misscols_dict_final[eachfile] = misscols_dict[eachfile]\n",
    "# 如果有缺失列，则报错，停止运行\n",
    "if misscols_dict_final:\n",
    "    logger.error('miss columns: %s' % (misscols_dict_final))\n",
    "    raise ValueError('miss columns: %s' % (misscols_dict_final))\n",
    "\n",
    "print('数据检查-Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://ph-max-auto/v0.0.1-2020-06-08//Common_files/Not_arrived202012.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =========== 数据准备 =============\n",
    "def unpivot(df, keys):\n",
    "    # 功能：数据宽变长\n",
    "    # 参数说明 df:dataframe,  keys 待转换表中需要保留的主键key，以list[]类型传入\n",
    "    # 转换是为了避免字段类不匹配，统一将数据转换为string类型，如果保证数据类型完全一致，可以省略该句\n",
    "    df = df.select(*[col(_).astype(\"string\") for _ in df.columns])\n",
    "    cols = [_ for _ in df.columns if _ not in keys]\n",
    "    stack_str = ','.join(map(lambda x: \"'%s', `%s`\" % (x, x), cols))\n",
    "    # feature, value 转换后的列名，可自定义\n",
    "    df = df.selectExpr(*keys, \"stack(%s, %s) as (feature, value)\" % (len(cols), stack_str))\n",
    "    return df\n",
    "\n",
    "def deal_ID_length(df):\n",
    "    # ID不足7位的补足0到6位\n",
    "    # 国药诚信医院编码长度是7位数字，cpa医院编码是6位数字，其他还有包含字母的ID\n",
    "    df = df.withColumn(\"ID\", df[\"ID\"].cast(StringType()))\n",
    "    # 去掉末尾的.0\n",
    "    df = df.withColumn(\"ID\", func.regexp_replace(\"ID\", \"\\\\.0\", \"\"))\n",
    "    df = df.withColumn(\"ID\", func.when(func.length(df.ID) < 7, func.lpad(df.ID, 6, \"0\")).otherwise(df.ID))\n",
    "    return df\n",
    "\n",
    "# 一. 生成 original_range_raw（样本中已到的Year、Month、PHA的搭配）\n",
    "# 2017到当前年的全量出版医院\n",
    "Published_years = list(range(2017, current_year+1, 1))\n",
    "for index, eachyear in enumerate(Published_years):\n",
    "    allmonth = [str(eachyear*100 + i) for i in list(range(1,13,1))]\n",
    "    published_path = max_path + \"/Common_files/Published\"+str(eachyear)+\".csv\"\n",
    "    published = spark.read.csv(published_path, header=True)\n",
    "    published = published.where(col('Source') == 'CPA').select('ID').distinct()\n",
    "    published = deal_ID_length(published)\n",
    "    for i in allmonth:\n",
    "        published = published.withColumn(i, func.lit(1))\n",
    "    if index == 0:\n",
    "        published_full = published\n",
    "    else:\n",
    "        published_full = published_full.join(published, on='ID', how='full')\n",
    "\n",
    "published_all = unpivot(published_full, ['ID'])\n",
    "published_all = published_all.where(col('value')==1).withColumnRenamed('feature', 'Date') \\\n",
    "                            .drop('value')\n",
    "\n",
    "# 模型前之前的未到名单（跑模型年的时候，不去除未到名单） \n",
    "if monthly_update == 'True':        \n",
    "    # 1.当前年的未到名单\n",
    "    not_arrived_current = spark.read.csv(not_arrived_path, header=True)\n",
    "    not_arrived_current = not_arrived_current.select('ID', 'Date').distinct()\n",
    "    not_arrived_current = deal_ID_length(not_arrived_current)\n",
    "    # 2.其他模型年之后的未到名单\n",
    "    model_year = model_month_right//100\n",
    "    not_arrived_others_years = set((range(model_year+1, current_year+1, 1)))-set([current_year])\n",
    "    if not_arrived_others_years:\n",
    "        for index, eachyear in enumerate(not_arrived_others_years):\n",
    "            not_arrived_others_path = max_path + \"/Common_files/Not_arrived\"+str(eachyear)+\"12.csv\"\n",
    "            print(not_arrived_others_path)\n",
    "            not_arrived = spark.read.csv(not_arrived_others_path, header=True)\n",
    "            not_arrived = not_arrived.select('ID', 'Date').distinct()\n",
    "            not_arrived = deal_ID_length(not_arrived)\n",
    "            if index == 0:\n",
    "                not_arrived_others = not_arrived\n",
    "            else:\n",
    "                not_arrived_others = not_arrived_others.union(not_arrived)\n",
    "        not_arrived_all = not_arrived_current.union(not_arrived_others)\n",
    "    else:\n",
    "        not_arrived_all = not_arrived_current\n",
    "\n",
    "        \n",
    "original_range_raw_noncpa = raw_data.where(col('Source') != 'CPA').select('ID', 'year_month').distinct() \\\n",
    "                                    .withColumnRenamed('year_month', 'Date')\n",
    "# 出版医院 减去 未到名单\n",
    "if monthly_update == 'True':\n",
    "    original_range_raw = published_all.join(not_arrived_all, on=['ID', 'Date'], how='left_anti')\n",
    "else:\n",
    "    original_range_raw = published_all\n",
    "    \n",
    "original_range_raw = original_range_raw.union(original_range_raw_noncpa.select(original_range_raw.columns))\n",
    "    \n",
    "# 匹配 PHA\n",
    "cpa_pha_mapping = spark.read.parquet(cpa_pha_mapping_path)\n",
    "cpa_pha_mapping = cpa_pha_mapping.filter(cpa_pha_mapping[\"推荐版本\"] == 1) \\\n",
    "                                .select(\"ID\", \"PHA\").distinct()\n",
    "cpa_pha_mapping = deal_ID_length(cpa_pha_mapping)\n",
    "\n",
    "original_range_raw = original_range_raw.join(cpa_pha_mapping, on='ID', how='left')\n",
    "original_range_raw = original_range_raw.where(~col('PHA').isNull()) \\\n",
    "                                        .withColumn('Year', func.substring(col('Date'), 0, 4)) \\\n",
    "                                        .withColumn('Month', func.substring(col('Date'), 5, 2).cast(IntegerType())) \\\n",
    "                                        .select('PHA', 'Year', 'Month').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =========== 数据执行 =============\n",
    "print('数据执行-start')\n",
    "\n",
    "# 数据读取\n",
    "raw_data = spark.read.parquet(product_mapping_out_path)\n",
    "raw_data.persist()\n",
    "products_of_interest = spark.read.csv(products_of_interest_path, header=True)\n",
    "products_of_interest = products_of_interest.toPandas()[\"poi\"].values.tolist()\n",
    "\n",
    "# raw_data 处理\n",
    "raw_data = raw_data.withColumn(\"S_Molecule_for_gr\",\n",
    "                               func.when(raw_data[\"标准商品名\"].isin(products_of_interest), raw_data[\"标准商品名\"]).\n",
    "                               otherwise(raw_data.S_Molecule))\n",
    "\n",
    "price = spark.read.parquet(price_path)\n",
    "price = price.withColumnRenamed('Price', 'Price_tier')\n",
    "\n",
    "growth_rate = spark.read.parquet(growth_rate_path)\n",
    "growth_rate.persist()\n",
    "\n",
    "price_city = spark.read.parquet(price_city_path)\n",
    "price_city = price_city.withColumnRenamed('Price', 'Price_city')\n",
    "\n",
    "\n",
    "# raw_data 处理\n",
    "if monthly_update == \"False\":\n",
    "    raw_data = raw_data.where(raw_data.Year < ((model_month_right // 100) + 1))\n",
    "    if project_name == \"Sanofi\" or project_name == \"AZ\":\n",
    "        raw_data = raw_data.where(raw_data.Year > 2016)\n",
    "elif monthly_update == \"True\":\n",
    "    if project_name == \"Sanofi\" or project_name == \"AZ\":\n",
    "        raw_data = raw_data.where(raw_data.Year > 2016)\n",
    "\n",
    "# 4 补数\n",
    "def add_data(raw_data, growth_rate):\n",
    "    # 4.1 原始数据格式整理， 用于补数: trans_raw_data_for_adding\n",
    "    growth_rate = growth_rate.select([\"CITYGROUP\", \"S_Molecule_for_gr\"] + [name for name in growth_rate.columns if name.startswith(\"GR\")]) \\\n",
    "        .distinct()\n",
    "    raw_data_for_add = raw_data.where(raw_data.PHA.isNotNull()) \\\n",
    "        .orderBy(raw_data.Year.desc()) \\\n",
    "        .withColumnRenamed(\"City_Tier_2010\", \"CITYGROUP\") \\\n",
    "        .join(growth_rate, on=[\"S_Molecule_for_gr\", \"CITYGROUP\"], how=\"left\")\n",
    "    raw_data_for_add.persist()\n",
    "\n",
    "    # 4.2 补充各个医院缺失的月份数据:\n",
    "    # add_data\n",
    "    # 原始数据的 PHA-Month-Year\n",
    "    # original_range = raw_data_for_add.select(\"Year\", \"Month\", \"PHA\").distinct()\n",
    "\n",
    "    years = raw_data_for_add.select(\"Year\").distinct() \\\n",
    "        .orderBy(raw_data_for_add.Year) \\\n",
    "        .toPandas()[\"Year\"].values.tolist()\n",
    "    \n",
    "    original_range = original_range_raw.where(original_range_raw.Year.isin(years))\n",
    "    # print(years)\n",
    "\n",
    "    growth_rate_index = [index for index, name in enumerate(raw_data_for_add.columns) if name.startswith(\"GR\")]\n",
    "    # print(growth_rate_index)\n",
    "\n",
    "    # 对每年的缺失数据分别进行补数\n",
    "    empty = 0\n",
    "    for eachyear in years:\n",
    "        # cal_time_range\n",
    "        # 当前年：月份-PHA\n",
    "        current_range_pha_month = original_range.where(original_range.Year == eachyear) \\\n",
    "            .select(\"Month\", \"PHA\").distinct()\n",
    "        # 当前年：月份\n",
    "        current_range_month = current_range_pha_month.select(\"Month\").distinct()\n",
    "        # 其他年：月份-当前年有的月份，PHA-当前年没有的医院\n",
    "        other_years_range = original_range.where(original_range.Year != eachyear) \\\n",
    "            .join(current_range_month, on=\"Month\", how=\"inner\") \\\n",
    "            .join(current_range_pha_month, on=[\"Month\", \"PHA\"], how=\"left_anti\")\n",
    "        # 其他年：与当前年的年份差值，比重计算\n",
    "        other_years_range = other_years_range \\\n",
    "            .withColumn(\"time_diff\", (other_years_range.Year - eachyear)) \\\n",
    "            .withColumn(\"weight\", func.when((other_years_range.Year > eachyear), (other_years_range.Year - eachyear - 0.5)).\n",
    "                        otherwise(other_years_range.Year * (-1) + eachyear))\n",
    "        # 选择比重最小的年份：用于补数的 PHA-Month-Year\n",
    "        current_range_for_add = other_years_range.repartition(1).orderBy(other_years_range.weight.asc())\n",
    "        current_range_for_add = current_range_for_add.groupBy(\"PHA\", \"Month\") \\\n",
    "            .agg(func.first(current_range_for_add.Year).alias(\"Year\"))\n",
    "\n",
    "        # get_seed_data\n",
    "        # 从 rawdata 根据 current_range_for_add 获取用于补数的数据\n",
    "        current_raw_data_for_add = raw_data_for_add.where(raw_data_for_add.Year != eachyear) \\\n",
    "            .join(current_range_for_add, on=[\"Month\", \"PHA\", \"Year\"], how=\"inner\")\n",
    "        current_raw_data_for_add = current_raw_data_for_add \\\n",
    "            .withColumn(\"time_diff\", (current_raw_data_for_add.Year - eachyear)) \\\n",
    "            .withColumn(\"weight\", func.when((current_raw_data_for_add.Year > eachyear), (current_raw_data_for_add.Year - eachyear - 0.5)).\n",
    "                        otherwise(current_raw_data_for_add.Year * (-1) + eachyear))\n",
    "\n",
    "        # cal_seed_with_gr\n",
    "        # 当前年与(当前年+1)的增长率所在列的index\n",
    "        base_index = eachyear - min(years) + min(growth_rate_index)\n",
    "        current_raw_data_for_add = current_raw_data_for_add.withColumn(\"Sales_bk\", current_raw_data_for_add.Sales)\n",
    "\n",
    "        # 为补数计算增长率\n",
    "        current_raw_data_for_add = current_raw_data_for_add \\\n",
    "            .withColumn(\"min_index\", func.when((current_raw_data_for_add.Year < eachyear), (current_raw_data_for_add.time_diff + base_index)).\n",
    "                        otherwise(base_index)) \\\n",
    "            .withColumn(\"max_index\", func.when((current_raw_data_for_add.Year < eachyear), (base_index - 1)).\n",
    "                        otherwise(current_raw_data_for_add.time_diff + base_index - 1)) \\\n",
    "            .withColumn(\"total_gr\", func.lit(1))\n",
    "\n",
    "        for i in growth_rate_index:\n",
    "            col_name = current_raw_data_for_add.columns[i]\n",
    "            current_raw_data_for_add = current_raw_data_for_add.withColumn(col_name, func.when((current_raw_data_for_add.min_index > i) | (current_raw_data_for_add.max_index < i), 1).\n",
    "                                                         otherwise(current_raw_data_for_add[col_name]))\n",
    "            current_raw_data_for_add = current_raw_data_for_add.withColumn(col_name, func.when(current_raw_data_for_add.Year > eachyear, current_raw_data_for_add[col_name] ** (-1)).\n",
    "                                                         otherwise(current_raw_data_for_add[col_name]))\n",
    "            current_raw_data_for_add = current_raw_data_for_add.withColumn(\"total_gr\", current_raw_data_for_add.total_gr * current_raw_data_for_add[col_name])\n",
    "\n",
    "        current_raw_data_for_add = current_raw_data_for_add.withColumn(\"final_gr\", func.when(current_raw_data_for_add.total_gr < 2, current_raw_data_for_add.total_gr).\n",
    "                                                     otherwise(2))\n",
    "\n",
    "        # 为当前年的缺失数据补数：根据增长率计算 Sales，匹配 price，计算 Units=Sales/price\n",
    "        current_adding_data = current_raw_data_for_add \\\n",
    "            .withColumn(\"Sales\", current_raw_data_for_add.Sales * current_raw_data_for_add.final_gr) \\\n",
    "            .withColumn(\"Year\", func.lit(eachyear))\n",
    "        current_adding_data = current_adding_data.withColumn(\"year_month\", current_adding_data.Year * 100 + current_adding_data.Month)\n",
    "        current_adding_data = current_adding_data.withColumn(\"year_month\", current_adding_data[\"year_month\"].cast(DoubleType()))\n",
    "\n",
    "        current_adding_data = current_adding_data.withColumnRenamed(\"CITYGROUP\", \"City_Tier_2010\") \\\n",
    "            .join(price, on=[\"min2\", \"year_month\", \"City_Tier_2010\"], how=\"inner\") \\\n",
    "            .join(price_city, on=[\"min2\", \"year_month\", \"City\", \"Province\"], how=\"left\")\n",
    "\n",
    "        current_adding_data = current_adding_data.withColumn('Price', func.when(current_adding_data.Price_city.isNull(), \n",
    "                                                                                current_adding_data.Price_tier) \\\n",
    "                                                                         .otherwise(current_adding_data.Price_city))\n",
    "\n",
    "        current_adding_data = current_adding_data.withColumn(\"Units\", func.when(current_adding_data.Sales == 0, 0).\n",
    "                                                     otherwise(current_adding_data.Sales / current_adding_data.Price)) \\\n",
    "            .na.fill({'Units': 0})\n",
    "\n",
    "        if empty == 0:\n",
    "            adding_data = current_adding_data\n",
    "        else:\n",
    "            adding_data = adding_data.union(current_adding_data)\n",
    "        empty = empty + 1\n",
    "\n",
    "    return adding_data, original_range\n",
    "\n",
    "# 执行函数 add_data\n",
    "if monthly_update == \"False\":\n",
    "    print('4 补数')\n",
    "    # 补数：add_data\n",
    "    add_data_out = add_data(raw_data, growth_rate)\n",
    "    adding_data = add_data_out[0]\n",
    "    original_range = add_data_out[1]\n",
    "\n",
    "elif monthly_update == \"True\" and if_add_data == \"True\":\n",
    "    #published_left = spark.read.csv(published_left_path, header=True)\n",
    "    #published_right = spark.read.csv(published_right_path, header=True)\n",
    "    #not_arrived =  spark.read.csv(not_arrived_path, header=True)\n",
    "\n",
    "    print('4 补数')\n",
    "\n",
    "    for index, month in enumerate(range(first_month, current_month + 1)):\n",
    "        # publish交集，去除当月未到\n",
    "        # month_hospital = published_left.intersect(published_right) \\\n",
    "        #     .exceptAll(not_arrived.where(not_arrived.Date == current_year*100 + month).select(\"ID\")) \\\n",
    "        #     .toPandas()[\"ID\"].tolist()\n",
    "\n",
    "        raw_data_month = raw_data.where(raw_data.Month == month)\n",
    "\n",
    "        growth_rate_month = growth_rate.where(growth_rate.month_for_monthly_add == month)\n",
    "\n",
    "        # 补数：add_data\n",
    "        adding_data_monthly = add_data(raw_data_month, growth_rate_month)[0]\n",
    "\n",
    "        # 输出adding_data\n",
    "        if index == 0:\n",
    "            # adding_data = adding_data_monthly\n",
    "            adding_data_monthly = adding_data_monthly.repartition(1)\n",
    "            adding_data_monthly.write.format(\"parquet\") \\\n",
    "                .mode(\"overwrite\").save(adding_data_path)\n",
    "        else:\n",
    "            # adding_data = adding_data.union(adding_data_monthly)\n",
    "            adding_data_monthly = adding_data_monthly.repartition(1)\n",
    "            adding_data_monthly.write.format(\"parquet\") \\\n",
    "                .mode(\"append\").save(adding_data_path)\n",
    "        print(\"输出 adding_data：\" + adding_data_path)\n",
    "\n",
    "\n",
    "if monthly_update == \"False\":\n",
    "    adding_data = adding_data.repartition(2)\n",
    "    adding_data.write.format(\"parquet\") \\\n",
    "        .mode(\"overwrite\").save(adding_data_path)\n",
    "    print(\"输出 adding_data：\" + adding_data_path)\n",
    "elif monthly_update == \"True\" and if_add_data == \"True\":\n",
    "    adding_data = spark.read.parquet(adding_data_path)\n",
    "\n",
    "# 1.8 合并补数部分和原始部分:\n",
    "# combind_data\n",
    "if if_add_data == \"True\":\n",
    "    raw_data_adding = (raw_data.withColumn(\"add_flag\", func.lit(0))) \\\n",
    "        .union(adding_data.withColumn(\"add_flag\", func.lit(1)).select(raw_data.columns + [\"add_flag\"]))\n",
    "else:\n",
    "    raw_data_adding = raw_data.withColumn(\"add_flag\", func.lit(0))\n",
    "raw_data_adding.persist()\n",
    "\n",
    "# 输出\n",
    "# raw_data_adding = raw_data_adding.repartition(2)\n",
    "# raw_data_adding.write.format(\"parquet\") \\\n",
    "#     .mode(\"overwrite\").save(raw_data_adding_path)\n",
    "# print(\"输出 raw_data_adding：\" + raw_data_adding_path)\n",
    "\n",
    "if monthly_update == \"False\":\n",
    "    # 1.9 进一步为最后一年独有的医院补最后一年的缺失月（可能也要考虑第一年）:add_data_new_hosp\n",
    "    years = original_range.select(\"Year\").distinct() \\\n",
    "        .orderBy(original_range.Year) \\\n",
    "        .toPandas()[\"Year\"].values.tolist()\n",
    "\n",
    "    # 只在最新一年出现的医院\n",
    "    new_hospital = (original_range.where(original_range.Year == max(years)).select(\"PHA\").distinct()) \\\n",
    "        .subtract(original_range.where(original_range.Year != max(years)).select(\"PHA\").distinct())\n",
    "    print(\"以下是最新一年出现的医院:\" + str(new_hospital.toPandas()[\"PHA\"].tolist()))\n",
    "    # 输出\n",
    "    new_hospital = new_hospital.repartition(2)\n",
    "    new_hospital.write.format(\"parquet\") \\\n",
    "        .mode(\"overwrite\").save(new_hospital_path)\n",
    "\n",
    "    print(\"输出 new_hospital：\" + new_hospital_path)\n",
    "\n",
    "    # 最新一年没有的月份\n",
    "    missing_months = (original_range.where(original_range.Year != max(years)).select(\"Month\").distinct()) \\\n",
    "        .subtract(original_range.where(original_range.Year == max(years)).select(\"Month\").distinct())\n",
    "\n",
    "    # 如果最新一年有缺失月份，需要处理\n",
    "    if missing_months.count() == 0:\n",
    "        print(\"missing_months=0\")\n",
    "        raw_data_adding_final = raw_data_adding\n",
    "    else:\n",
    "        number_of_existing_months = 12 - missing_months.count()\n",
    "        # 用于groupBy的列名：raw_data_adding列名去除list中的列名\n",
    "        group_columns = set(raw_data_adding.columns) \\\n",
    "            .difference(set(['Month', 'Sales', 'Units', '季度', \"sales_value__rmb_\", \"total_units\", \"counting_units\", \"year_month\"]))\n",
    "        # 补数重新计算\n",
    "        adding_data_new = raw_data_adding \\\n",
    "            .where(raw_data_adding.add_flag == 1) \\\n",
    "            .where(raw_data_adding.PHA.isin(new_hospital[\"PHA\"].tolist())) \\\n",
    "            .groupBy(list(group_columns)).agg({\"Sales\": \"sum\", \"Units\": \"sum\"})\n",
    "        adding_data_new = adding_data_new \\\n",
    "            .withColumn(\"Sales\", adding_data_new[\"sum(Sales)\"] / number_of_existing_months) \\\n",
    "            .withColumn(\"Units\", adding_data_new[\"sum(Units)\"] / number_of_existing_months) \\\n",
    "            .crossJoin(missing_months)\n",
    "        # 生成最终补数结果\n",
    "        same_names = list(set(raw_data_adding.columns).intersection(set(adding_data_new.columns)))\n",
    "        raw_data_adding_final = raw_data_adding.select(same_names) \\\n",
    "            .union(adding_data_new.select(same_names))\n",
    "elif monthly_update == \"True\":\n",
    "    raw_data_adding_final = raw_data_adding \\\n",
    "    .where((raw_data_adding.Year == current_year) & (raw_data_adding.Month >= first_month) & (raw_data_adding.Month <= current_month) )\n",
    "\n",
    "# 输出补数结果 raw_data_adding_final\n",
    "raw_data_adding_final = raw_data_adding_final.repartition(2)\n",
    "raw_data_adding_final.write.format(\"parquet\") \\\n",
    "    .mode(\"overwrite\").save(raw_data_adding_final_path)\n",
    "\n",
    "print(\"输出 raw_data_adding_final：\" + raw_data_adding_final_path)\n",
    "\n",
    "print('数据执行-Finish')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
