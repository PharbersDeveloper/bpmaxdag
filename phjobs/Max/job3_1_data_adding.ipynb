{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phcli Jupyter Python Template\n",
    "# \n",
    "# 使用手册：\n",
    "# 1. 请将全局变量定义在第一个输入区内\n",
    "# 2. Phcli 会自动在第二个输入区初始化 Spark Session\n",
    "# 3. 所有 print 会在 phcli maxauto dag 后自动转为 logger.debug() 方法\n",
    "# 4. 请在第三个输入区开始编码，phcli maxauto dag 后会全部归类为一个方法\n",
    "\n",
    "\n",
    "# Config defined in here\n",
    "\n",
    "############## == config == ###################\n",
    "job_name = \"job3_1_data_adding\"\n",
    "job_runtime = \"python3\"\n",
    "job_command = \"submit\"\n",
    "job_timeout = 720.0\n",
    "############## == config == ###################\n",
    "\n",
    "\n",
    "# Variables defined in here\n",
    "\n",
    "############## == input args == ###################\n",
    "max_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "project_name = \"Empty\"\n",
    "model_month_right = \"0\"\n",
    "max_month = \"0\"\n",
    "year_missing = \"0\"\n",
    "current_year = \"2020\"\n",
    "first_month = \"Empty\"\n",
    "current_month = \"Empty\"\n",
    "if_others = \"False\"\n",
    "monthly_update = \"Empty\"\n",
    "not_arrived_path = \"Empty\"\n",
    "published_path = \"Empty\"\n",
    "out_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/\"\n",
    "out_dir = \"Empty\"\n",
    "need_test = 0\n",
    "if_add_data = \"True\"\n",
    "############## == input args == ###################\n",
    "\n",
    "############## == output args == ###################\n",
    "c = 'abc'\n",
    "d = 'def'\n",
    "############## == output args == ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Spark Session\n",
    "# YARN URL: http://161.189.223.227:8088/cluster\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# prepare\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .appName(\"ywyuan write Max.job3_1_data_adding in jupyter using python3\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .config('spark.sql.codegen.wholeStage', False) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID\", \"AKIAWPBDTVEAEU44ZAGT\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"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\")\n",
    "if access_key:\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "    spark._jsc.hadoopConfiguration().set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.cn-northwest-1.amazonaws.com.cn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"Gilead\"\n",
    "model_month_right = \"201912\"\n",
    "first_month = \"1\"\n",
    "current_month = \"1\"\n",
    "monthly_update = \"True\"\n",
    "out_dir = \"202101\"\n",
    "current_year = '2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job3_data_adding\n"
     ]
    }
   ],
   "source": [
    "print('job3_data_adding')\n",
    "\n",
    "if if_add_data != \"False\" and if_add_data != \"True\":\n",
    "    print('wrong input: if_add_data, False or True') \n",
    "    raise ValueError('wrong input: if_add_data, False or True')\n",
    "\n",
    "if if_others == \"True\":\n",
    "    out_dir = out_dir + \"/others_box/\"\n",
    "\n",
    "out_path_dir = out_path + \"/\" + project_name + '/' + out_dir\n",
    "\n",
    "# 输入\n",
    "product_mapping_out_path = out_path_dir + \"/product_mapping_out\"\n",
    "products_of_interest_path = max_path + \"/\" + project_name + \"/poi.csv\"\n",
    "if year_missing:\n",
    "    year_missing = year_missing.replace(\" \",\"\").split(\",\")\n",
    "else:\n",
    "    year_missing = []\n",
    "year_missing = [int(i) for i in year_missing]\n",
    "model_month_right = int(model_month_right)\n",
    "max_month = int(max_month)\n",
    "\n",
    "# 月更新相关参数\n",
    "if monthly_update != \"False\" and monthly_update != \"True\":\n",
    "    print('wrong input: monthly_update, False or True') \n",
    "    raise ValueError('wrong input: monthly_update, False or True')\n",
    "if monthly_update == \"True\":\n",
    "    current_year = int(current_year)\n",
    "    first_month = int(first_month)\n",
    "    current_month = int(current_month)\n",
    "    if not_arrived_path == \"Empty\":    \n",
    "        not_arrived_path = max_path + \"/Common_files/Not_arrived\" + str(current_year*100 + current_month) + \".csv\"\n",
    "    if published_path == \"Empty\":\n",
    "        published_right_path = max_path + \"/Common_files/Published\" + str(current_year) + \".csv\"\n",
    "        published_left_path = max_path + \"/Common_files/Published\" + str(current_year - 1) + \".csv\"\n",
    "    else:\n",
    "        published_path  = published_path.replace(\" \",\"\").split(\",\")\n",
    "        published_left_path = published_path[0]\n",
    "        published_right_path = published_path[1]\n",
    "# not_arrived_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/Common_files/Not_arrived202004.csv\"\n",
    "# published_left_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/Common_files/Published2019.csv\"\n",
    "# published_right_path = \"s3a://ph-max-auto/v0.0.1-2020-06-08/Common_files/Published2020.csv\"\n",
    "\n",
    "# 输出\n",
    "price_path = out_path_dir + \"/price\"\n",
    "price_city_path = out_path_dir + \"/price_city\"\n",
    "growth_rate_path = out_path_dir + \"/growth_rate\"\n",
    "adding_data_path =  out_path_dir + \"/adding_data\"\n",
    "raw_data_adding_path =  out_path_dir + \"/raw_data_adding\"\n",
    "new_hospital_path = out_path_dir + \"/new_hospital\"\n",
    "raw_data_adding_final_path =  out_path_dir + \"/raw_data_adding_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据检查-start\n",
      "数据检查-Pass\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========== 数据检查 =============\n",
    "\n",
    "print('数据检查-start')\n",
    "\n",
    "# csv文件检查\n",
    "length_error_dict = {}\n",
    "if monthly_update == \"True\":\n",
    "    csv_path_list = [published_left_path, published_right_path, not_arrived_path]\n",
    "    for eachpath in csv_path_list:\n",
    "        eachfile = spark.read.csv(eachpath, header=True)\n",
    "        ID_length = eachfile.withColumn(\"ID_length\", func.length(\"ID\")).select(\"ID_length\").distinct().toPandas()[\"ID_length\"].values.tolist()\n",
    "        for i in ID_length:\n",
    "            if i < 6:\n",
    "                length_error_dict[eachpath] = ID_length\n",
    "    if length_error_dict:\n",
    "        print('ID length error: %s' % (length_error_dict))\n",
    "        raise ValueError('ID length error: %s' % (length_error_dict))\n",
    "\n",
    "# 存储文件的缺失列\n",
    "misscols_dict = {}\n",
    "\n",
    "# product_mapping_out file\n",
    "raw_data = spark.read.parquet(product_mapping_out_path)\n",
    "colnames_raw_data = raw_data.columns\n",
    "misscols_dict.setdefault(\"product_mapping_out\", [])\n",
    "\n",
    "colnamelist = ['min1', 'PHA', 'City', 'year_month', 'ID',  'Brand', 'Form',\n",
    "'Specifications', 'Pack_Number', 'Manufacturer', 'Molecule', 'Source', \n",
    "'Sales', 'Units', 'Path', 'Sheet', 'BI_hospital_code', 'Province',\n",
    "'Month', 'Year', 'City_Tier_2010', 'min2', 'S_Molecule', 'std_route', \"标准商品名\"]\n",
    "#'Raw_Hosp_Name','ORG_Measure','Units_Box', 'Corp', 'Route'\n",
    "\n",
    "for each in colnamelist:\n",
    "    if each not in colnames_raw_data:\n",
    "        misscols_dict[\"product_mapping_out\"].append(each)\n",
    "\n",
    "# 判断输入文件是否有缺失列\n",
    "misscols_dict_final = {}\n",
    "for eachfile in misscols_dict.keys():\n",
    "    if len(misscols_dict[eachfile]) != 0:\n",
    "        misscols_dict_final[eachfile] = misscols_dict[eachfile]\n",
    "# 如果有缺失列，则报错，停止运行\n",
    "if misscols_dict_final:\n",
    "    print('miss columns: %s' % (misscols_dict_final))\n",
    "    raise ValueError('miss columns: %s' % (misscols_dict_final))\n",
    "\n",
    "print('数据检查-Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据执行-start\n",
      "1 价格计算\n",
      "输出 price：s3a://ph-max-auto/v0.0.1-2020-06-08//Gilead/202101/price\n",
      "2 连续性计算\n",
      "3 增长率计算\n",
      "输出 growth_rate：s3a://ph-max-auto/v0.0.1-2020-06-08//Gilead/202101/growth_rate\n",
      "数据执行-Finish\n"
     ]
    }
   ],
   "source": [
    "# =========== 数据执行 =============\n",
    "print('数据执行-start')\n",
    "\n",
    "# 数据读取\n",
    "raw_data = spark.read.parquet(product_mapping_out_path)\n",
    "raw_data.persist()\n",
    "products_of_interest = spark.read.csv(products_of_interest_path, header=True)\n",
    "products_of_interest = products_of_interest.toPandas()[\"poi\"].values.tolist()\n",
    "\n",
    "# raw_data 处理\n",
    "raw_data = raw_data.withColumn(\"S_Molecule_for_gr\",\n",
    "                               func.when(raw_data[\"标准商品名\"].isin(products_of_interest), raw_data[\"标准商品名\"]).\n",
    "                               otherwise(raw_data.S_Molecule))\n",
    "\n",
    "print('1 价格计算')\n",
    "\n",
    "# 1 价格计算：cal_price 补数部分的数量需要用价格得出\n",
    "price = raw_data.groupBy(\"min2\", \"year_month\", \"City_Tier_2010\") \\\n",
    "    .agg((func.sum(\"Sales\") / func.sum(\"Units\")).alias(\"Price\"))\n",
    "price2 = raw_data.groupBy(\"min2\", \"year_month\") \\\n",
    "    .agg((func.sum(\"Sales\") / func.sum(\"Units\")).alias(\"Price2\"))\n",
    "price = price.join(price2, on=[\"min2\", \"year_month\"], how=\"left\")\n",
    "price = price.withColumn(\"Price\", func.when(func.isnull(price.Price), price.Price2).\n",
    "                         otherwise(price.Price))\n",
    "price = price.withColumn(\"Price\", func.when(func.isnull(price.Price), func.lit(0)).\n",
    "                         otherwise(price.Price)) \\\n",
    "    .drop(\"Price2\")\n",
    "\n",
    "# 城市层面\n",
    "price_city = raw_data.groupBy(\"min2\", \"year_month\", 'City', 'Province') \\\n",
    "                    .agg((func.sum(\"Sales\") / func.sum(\"Units\")).alias(\"Price\"))\n",
    "price_city = price_city.where(~price_city.Price.isNull())\n",
    "\n",
    "# 输出price\n",
    "price = price.repartition(2)\n",
    "price.write.format(\"parquet\") \\\n",
    "    .mode(\"overwrite\").save(price_path)\n",
    "\n",
    "price_city = price_city.repartition(2)\n",
    "price_city.write.format(\"parquet\") \\\n",
    "    .mode(\"overwrite\").save(price_city_path)\n",
    "\n",
    "print(\"输出 price：\" + price_path)\n",
    "\n",
    "# raw_data 处理\n",
    "if monthly_update == \"False\":\n",
    "    raw_data = raw_data.where(raw_data.Year < ((model_month_right // 100) + 1))\n",
    "    if project_name == \"Sanofi\" or project_name == \"AZ\":\n",
    "        raw_data = raw_data.where(raw_data.Year > 2016)\n",
    "elif monthly_update == \"True\":\n",
    "    if project_name == \"Sanofi\" or project_name == \"AZ\":\n",
    "        raw_data = raw_data.where(raw_data.Year > 2016)\n",
    "\n",
    "print('2 连续性计算')\n",
    "\n",
    "# 2 计算样本医院连续性: cal_continuity\n",
    "# 每个医院每年的月份数\n",
    "continuity = raw_data.select(\"Year\", \"Month\", \"PHA\").distinct() \\\n",
    "    .groupBy(\"PHA\", \"Year\").count()\n",
    "# 每个医院最大月份数，最小月份数\n",
    "continuity_whole_year = continuity.groupBy(\"PHA\") \\\n",
    "    .agg(func.max(\"count\").alias(\"MAX\"), func.min(\"count\").alias(\"MIN\"))\n",
    "continuity = continuity.repartition(2, \"PHA\")\n",
    "\n",
    "years = continuity.select(\"Year\").distinct().toPandas()[\"Year\"].sort_values().values.tolist()\n",
    "# 数据长变宽\n",
    "continuity = continuity.groupBy(\"PHA\").pivot(\"Year\").agg(func.sum('count')).fillna(0)\n",
    "# 列名修改\n",
    "for eachyear in years:\n",
    "    eachyear = str(eachyear)\n",
    "    continuity = continuity.withColumn(eachyear, continuity[eachyear].cast(DoubleType())) \\\n",
    "        .withColumnRenamed(eachyear, \"Year_\" + eachyear)\n",
    "# year列求和\n",
    "# month_sum = con.Year_2018 + con.Year_2019\n",
    "month_sum = \"\"\n",
    "for i in continuity.columns[1:]:\n",
    "    month_sum += (\"continuity.\" + i + \"+\")\n",
    "month_sum = month_sum.strip('+')\n",
    "continuity = continuity.withColumn(\"total\", eval(month_sum))\n",
    "# ['PHA', 'Year_2018', 'Year_2019', 'total', 'MAX', 'MIN']\n",
    "continuity = continuity.join(continuity_whole_year, on=\"PHA\", how=\"left\")\n",
    "\n",
    "# 3 计算样本分子增长率: cal_growth\n",
    "def calculate_growth(raw_data, max_month=12):\n",
    "    # TODO: 完整年用完整年增长，不完整年用不完整年增长\n",
    "    if max_month < 12:\n",
    "        raw_data = raw_data.where(raw_data.Month <= max_month)\n",
    "\n",
    "    # raw_data 处理\n",
    "    growth_raw_data = raw_data.na.fill({\"City_Tier_2010\": 5.0})\n",
    "    growth_raw_data = growth_raw_data.withColumn(\"CITYGROUP\", growth_raw_data.City_Tier_2010)\n",
    "\n",
    "    # 增长率计算过程\n",
    "    growth_calculating = growth_raw_data.groupBy(\"S_Molecule_for_gr\", \"CITYGROUP\", \"Year\") \\\n",
    "        .agg(func.sum(growth_raw_data.Sales).alias(\"value\"))\n",
    "\n",
    "    years = growth_calculating.select(\"Year\").distinct().toPandas()[\"Year\"].sort_values().values.tolist()\n",
    "    years = [str(i) for i in years]\n",
    "    years_name = [\"Year_\" + i for i in years]\n",
    "    # 数据长变宽\n",
    "    growth_calculating = growth_calculating.groupBy(\"S_Molecule_for_gr\", \"CITYGROUP\").pivot(\"Year\").agg(func.sum('value')).fillna(0)\n",
    "    growth_calculating = growth_calculating.select([\"S_Molecule_for_gr\", \"CITYGROUP\"] + years)\n",
    "    # 对year列名修改\n",
    "    for i in range(0, len(years)):\n",
    "        growth_calculating = growth_calculating.withColumnRenamed(years[i], years_name[i])\n",
    "\n",
    "    # 计算得到年增长： add_gr_cols\n",
    "    for i in range(0, len(years) - 1):\n",
    "        growth_calculating = growth_calculating.withColumn(\"GR\" + years[i][2:4] + years[i + 1][2:4],\n",
    "                                                    growth_calculating[years_name[i + 1]] / growth_calculating[years_name[i]])\n",
    "    growth_rate = growth_calculating     \n",
    "    # 增长率的调整：modify_gr\n",
    "    for y in [name for name in growth_rate.columns if name.startswith(\"GR\")]:\n",
    "        growth_rate = growth_rate.withColumn(y, func.when(func.isnull(growth_rate[y]) | (growth_rate[y] > 10) | (growth_rate[y] < 0.1), 1).\n",
    "                                             otherwise(growth_rate[y]))\n",
    "    return growth_rate\n",
    "\n",
    "print('3 增长率计算')\n",
    "# 执行函数 calculate_growth\n",
    "if monthly_update == \"False\":\n",
    "    # AZ-Sanofi 要特殊处理\n",
    "    if project_name != \"Sanofi\" and project_name != \"AZ\":\n",
    "        growth_rate = calculate_growth(raw_data)\n",
    "    else:\n",
    "        year_missing_df = pd.DataFrame(year_missing, columns=[\"Year\"])\n",
    "        year_missing_df = spark.createDataFrame(year_missing_df)\n",
    "        year_missing_df = year_missing_df.withColumn(\"Year\", year_missing_df[\"Year\"].cast(IntegerType()))\n",
    "        # 完整年\n",
    "        growth_rate_p1 = calculate_growth(raw_data.join(year_missing_df, on=[\"Year\"], how=\"left_anti\"))\n",
    "        # 不完整年\n",
    "        growth_rate_p2 = calculate_growth(raw_data.where(raw_data.Year.isin(year_missing + [y - 1 for y in year_missing] + [y + 1 for y in year_missing])), max_month)\n",
    "\n",
    "        growth_rate = growth_rate_p1.select(\"S_Molecule_for_gr\", \"CITYGROUP\") \\\n",
    "            .union(growth_rate_p2.select(\"S_Molecule_for_gr\", \"CITYGROUP\")) \\\n",
    "            .distinct()\n",
    "        growth_rate = growth_rate.join(\n",
    "            growth_rate_p1.select([\"S_Molecule_for_gr\", \"CITYGROUP\"] + [name for name in growth_rate_p1.columns if name.startswith(\"GR\")]),\n",
    "            on=[\"S_Molecule_for_gr\", \"CITYGROUP\"],\n",
    "            how=\"left\")\n",
    "        growth_rate = growth_rate.join(\n",
    "            growth_rate_p2.select([\"S_Molecule_for_gr\", \"CITYGROUP\"] + [name for name in growth_rate_p2.columns if name.startswith(\"GR\")]),\n",
    "            on=[\"S_Molecule_for_gr\", \"CITYGROUP\"],\n",
    "            how=\"left\")\n",
    "\n",
    "elif monthly_update == \"True\":\n",
    "    published_left = spark.read.csv(published_left_path, header=True)\n",
    "    published_left = published_left.select('ID').distinct()\n",
    "\n",
    "    published_right = spark.read.csv(published_right_path, header=True)\n",
    "    published_right = published_right.select('ID').distinct()\n",
    "\n",
    "    not_arrived =  spark.read.csv(not_arrived_path, header=True)\n",
    "\n",
    "    for index, month in enumerate(range(first_month, current_month + 1)):\n",
    "\n",
    "        raw_data_month = raw_data.where(raw_data.Month == month)\n",
    "\n",
    "        if if_add_data == \"False\":\n",
    "            growth_rate_month = calculate_growth(raw_data_month)\n",
    "        else:\n",
    "            # publish交集，去除当月未到\n",
    "            month_hospital = published_left.intersect(published_right) \\\n",
    "                .exceptAll(not_arrived.where(not_arrived.Date == current_year*100 + month).select(\"ID\")) \\\n",
    "                .toPandas()[\"ID\"].tolist()\n",
    "            growth_rate_month = calculate_growth(raw_data_month.where(raw_data_month.ID.isin(month_hospital)))\n",
    "            # 标记是哪个月补数要用的growth_rate\n",
    "\n",
    "        growth_rate_month = growth_rate_month.withColumn(\"month_for_monthly_add\", func.lit(month))\n",
    "\n",
    "        # 输出growth_rate结果\n",
    "        if index == 0:\n",
    "            # growth_rate = growth_rate_month\n",
    "            growth_rate_month = growth_rate_month.repartition(1)\n",
    "            growth_rate_month.write.format(\"parquet\") \\\n",
    "                .mode(\"overwrite\").save(growth_rate_path)\n",
    "        else:\n",
    "            # growth_rate = growth_rate.union(growth_rate_month)\n",
    "            growth_rate_month = growth_rate_month.repartition(1)\n",
    "            growth_rate_month.write.format(\"parquet\") \\\n",
    "                .mode(\"append\").save(growth_rate_path)\n",
    "\n",
    "        print(\"输出 growth_rate：\" + growth_rate_path)\n",
    "\n",
    "\n",
    "if monthly_update == \"False\":\n",
    "    growth_rate = growth_rate.repartition(2)\n",
    "    growth_rate.write.format(\"parquet\") \\\n",
    "        .mode(\"overwrite\").save(growth_rate_path)\n",
    "    print(\"输出 growth_rate：\" + growth_rate_path)\n",
    "elif monthly_update == \"True\":\n",
    "    growth_rate = spark.read.parquet(growth_rate_path)\n",
    "\n",
    "print('数据执行-Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
